# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
Common modules
"""
import collections
import logging
import math
import warnings
from copy import copy
from pathlib import Path

import numpy as np
import pandas as pd
import requests
import torch
import torch.nn as nn
from PIL import Image
from torch.cuda import amp

from utils.datasets import exif_transpose, letterbox
from utils.general import colorstr, increment_path, is_ascii, make_divisible, non_max_suppression, save_one_box, \
    scale_coords, xyxy2xywh
from utils.plots import Annotator, colors
from utils.torch_utils import time_sync

LOGGER = logging.getLogger(__name__)


def autopad(k, p=None):  # kernel, padding
    # Pad to 'same'
    if p is None:
        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad
    return p



#SEä¿®æ”¹çš„C3
class SEConv(nn.Module):
    # Standard convolution
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())
        self.se = SELayer(c2)

    def forward(self, x):
        return self.se(self.act(self.bn(self.conv(x))))

    def forward_fuse(self, x):
        return self.se(self.act(self.conv(x)))

class SEBottleneck(nn.Module):
    # Standard bottleneck
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = SEConv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))

class SEC3(nn.Module):
    # CSP Bottleneck with 3 convolutions
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # act=FReLU(c2)
        self.m = nn.Sequential(*(SEBottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))
        # self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])

    def forward(self, x):
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))




#CAä¿®æ”¹çš„C3
class CAConv(nn.Module):
    # Standard convolution
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())
        self.ca = CoorAttention(c2,c2)

    def forward(self, x):
        return self.ca(self.act(self.bn(self.conv(x))))

    def forward_fuse(self, x):
        return self.ca(self.act(self.conv(x)))

class CABottleneck(nn.Module):
    # Standard bottleneck
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = CAConv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))

class CAC3(nn.Module):
    # CSP Bottleneck with 3 convolutions
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # act=FReLU(c2)
        self.m = nn.Sequential(*(CABottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))
        # self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])

    def forward(self, x):
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))





class Conv(nn.Module):
    # Standard convolution
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

    def forward_fuse(self, x):
        return self.act(self.conv(x))


class DWConv(Conv):
    # Depth-wise convolution class
    def __init__(self, c1, c2, k=1, s=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
        super().__init__(c1, c2, k, s, g=math.gcd(c1, c2), act=act)


class TransformerLayer(nn.Module):
    # Transformer layer https://arxiv.org/abs/2010.11929 (LayerNorm layers removed for better performance)
    def __init__(self, c, num_heads):
        super().__init__()
        # è¾“å…¥: queryã€keyã€value
        self.q = nn.Linear(c, c, bias=False)
        self.k = nn.Linear(c, c, bias=False)
        self.v = nn.Linear(c, c, bias=False)
        self.ma = nn.MultiheadAttention(embed_dim=c, num_heads=num_heads)
        self.fc1 = nn.Linear(c, c, bias=False)
        self.fc2 = nn.Linear(c, c, bias=False)

    def forward(self, x):
        # å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ + æ®‹å·®(è¿™é‡Œç§»é™¤äº†LayerNorm for better performance)
        x = self.ma(self.q(x), self.k(x), self.v(x))[0] + x
        # feed forward å‰é¦ˆç¥ç»ç½‘ç»œ + æ®‹å·®(è¿™é‡Œç§»é™¤äº†LayerNorm for better performance)
        x = self.fc2(self.fc1(x)) + x
        return x


class TransformerBlock(nn.Module):
    # Vision Transformer https://arxiv.org/abs/2010.11929
    def __init__(self, c1, c2, num_heads, num_layers):
        super().__init__()
        self.conv = None
        if c1 != c2:
            self.conv = Conv(c1, c2)
        self.linear = nn.Linear(c2, c2)  # learnable position embedding
        self.tr = nn.Sequential(*[TransformerLayer(c2, num_heads) for _ in range(num_layers)]) # encoder * n
        self.c2 = c2

    def forward(self, x):
        if self.conv is not None: # embedding
            x = self.conv(x)
        b, _, w, h = x.shape
        p = x.flatten(2).unsqueeze(0).transpose(0, 3).squeeze(3)
        return self.tr(p + self.linear(p)).unsqueeze(3).transpose(0, 3).reshape(b, self.c2, w, h)


class Bottleneck(nn.Module):
    # Standard bottleneck
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))


class BottleneckCSP(nn.Module):
    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = nn.Conv2d(c1, c_, 1, 1, bias=False)
        self.cv3 = nn.Conv2d(c_, c_, 1, 1, bias=False)
        self.cv4 = Conv(2 * c_, c2, 1, 1)
        self.bn = nn.BatchNorm2d(2 * c_)  # applied to cat(cv2, cv3)
        self.act = nn.LeakyReLU(0.1, inplace=True)
        self.m = nn.Sequential(*[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])

    def forward(self, x):
        y1 = self.cv3(self.m(self.cv1(x)))
        y2 = self.cv2(x)
        return self.cv4(self.act(self.bn(torch.cat((y1, y2), dim=1))))


class C3(nn.Module):  #nçš„å€¼ä»£è¡¨å†…éƒ¨æ®‹å·®ç»“æ„æ‰€å¾ªç¯çš„æ¬¡æ•°,å³ä¸ºbase_depth
    # CSP Bottleneck with 3 convolutions
    """åœ¨C3TRæ¨¡å—å’Œyolo.pyçš„parse_modelæ¨¡å—è°ƒç”¨
        CSP Bottleneck with 3 convolutions
        :params c1: æ•´ä¸ªBottleneckCSPçš„è¾“å…¥channel
        :params c2: æ•´ä¸ªBottleneckCSPçš„è¾“å‡ºchannel
        :params n: æœ‰nä¸ªBottleneck
        :params shortcut: bool Bottleneckä¸­æ˜¯å¦æœ‰shortcutï¼Œé»˜è®¤True
        :params g: Bottleneckä¸­çš„3x3å·ç§¯ç±»å‹  =1æ™®é€šå·ç§¯  >1æ·±åº¦å¯åˆ†ç¦»å·ç§¯
        :params e: expansion ratio c2xe=ä¸­é—´å…¶ä»–æ‰€æœ‰å±‚çš„å·ç§¯æ ¸ä¸ªæ•°/ä¸­é—´æ‰€æœ‰å±‚çš„è¾“å…¥è¾“å‡ºchannelæ•°
        """
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # act=FReLU(c2)
        self.m = nn.Sequential(*[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])
        # self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])

    def forward(self, x):
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))


class C3TR(C3):
    # C3 module with TransformerBlock()
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)
        self.m = TransformerBlock(c_, c_, 4, n)


class C3SPP(C3):
    # C3 module with SPP()
    def __init__(self, c1, c2, k=(5, 9, 13), n=1, shortcut=True, g=1, e=0.5):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)
        self.m = SPP(c_, c_, k)


class C3Ghost(C3):   #ç»§æ‰¿çš„C3
    # C3 module with GhostBottleneck()
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)  # hidden channels
        self.m = nn.Sequential(*[GhostBottleneck(c_, c_) for _ in range(n)])


class SPP(nn.Module):
    # Spatial Pyramid Pooling (SPP) layer https://arxiv.org/abs/1406.4729
    """åœ¨yolo.pyçš„parse_modelæ¨¡å—è°ƒç”¨
        ç©ºé—´é‡‘å­—å¡”æ± åŒ– Spatial pyramid pooling layer used in YOLOv3-SPP
        :params c1: SPPæ¨¡å—çš„è¾“å…¥channel
        :params c2: SPPæ¨¡å—çš„è¾“å‡ºchannel
        :params k: ä¿å­˜ç€ä¸‰ä¸ªmaxpoolçš„å·ç§¯æ ¸å¤§å° é»˜è®¤æ˜¯(5, 9, 13)
    """
    def __init__(self, c1, c2, k=(5, 9, 13)):
        super().__init__()
        c_ = c1 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_ * (len(k) + 1), c2, 1, 1)
        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k])

    def forward(self, x):
        x = self.cv1(x)
        with warnings.catch_warnings():
            warnings.simplefilter('ignore')  # suppress torch 1.9.0 max_pool2d() warning
            return self.cv2(torch.cat([x] + [m(x) for m in self.m], 1))


class SPPF(nn.Module):
    # Spatial Pyramid Pooling - Fast (SPPF) layer for YOLOv5 by Glenn Jocher
    def __init__(self, c1, c2, k=5):  # equivalent to SPP(k=(5, 9, 13))
        super().__init__()
        c_ = c1 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_ * 4, c2, 1, 1)
        self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)

    def forward(self, x):
        x = self.cv1(x)
        with warnings.catch_warnings():
            warnings.simplefilter('ignore')  # suppress torch 1.9.0 max_pool2d() warning
            y1 = self.m(x)
            y2 = self.m(y1)
            return self.cv2(torch.cat([x, y1, y2, self.m(y2)], 1))


class Focus(nn.Module):
    # Focus wh information into c-space
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
        super().__init__()
        self.conv = Conv(c1 * 4, c2, k, s, p, g, act)
        # self.contract = Contract(gain=2)

    def forward(self, x):  # x(b,c,w,h) -> y(b,4c,w/2,h/2)
        return self.conv(torch.cat([x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]], 1))
        # return self.conv(self.contract(x))


class GhostConv(nn.Module):
    # Ghost Convolution https://github.com/huawei-noah/ghostnet
    def __init__(self, c1, c2, k=1, s=1, g=1, act=True):  # ch_in, ch_out, kernel, stride, groups
        super().__init__()
        c_ = c2 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, k, s, None, g, act)
        self.cv2 = Conv(c_, c_, 5, 1, None, c_, act)    #å»‰ä»·æ“ä½œ

    def forward(self, x):
        y = self.cv1(x)
        return torch.cat([y, self.cv2(y)], 1)


class GhostBottleneck(nn.Module):
    # Ghost Bottleneck https://github.com/huawei-noah/ghostnet
    def __init__(self, c1, c2, k=3, s=1):  # ch_in, ch_out, kernel, stride
        super().__init__()
        c_ = c2 // 2
        self.conv = nn.Sequential(GhostConv(c1, c_, 1, 1),  # pw
                                  DWConv(c_, c_, k, s, act=False) if s == 2 else nn.Identity(),  # dw
                                  GhostConv(c_, c2, 1, 1, act=False))  # pw-linear
        self.shortcut = nn.Sequential(DWConv(c1, c1, k, s, act=False),
                                      Conv(c1, c2, 1, 1, act=False)) if s == 2 else nn.Identity()

    def forward(self, x):
        return self.conv(x) + self.shortcut(x)





#PSA Module
class SEWeightModule(nn.Module):

    def __init__(self, channels, reduction=16):
        super(SEWeightModule, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc1 = nn.Conv2d(channels, channels//reduction, kernel_size=1, padding=0)
        self.relu = nn.ReLU(inplace=True)
        self.fc2 = nn.Conv2d(channels//reduction, channels, kernel_size=1, padding=0)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        out = self.avg_pool(x)
        out = self.fc1(out)
        out = self.relu(out)
        out = self.fc2(out)
        weight = self.sigmoid(out)

        return weight

def conv(in_planes, out_planes, kernel_size=3, stride=1, padding=1, dilation=1, groups=1):
    """standard convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride,
                     padding=padding, dilation=dilation, groups=groups, bias=False)
class PSAModule(nn.Module):

    def __init__(self, inplans, planes, conv_kernels=[3, 5, 7, 9], stride=1, conv_groups=[1, 4, 8, 16]):
        super(PSAModule, self).__init__()
        self.conv_1 = conv(inplans, planes//4, kernel_size=conv_kernels[0], padding=conv_kernels[0]//2,
                            stride=stride, groups=conv_groups[0])
        self.conv_2 = conv(inplans, planes//4, kernel_size=conv_kernels[1], padding=conv_kernels[1]//2,
                            stride=stride, groups=conv_groups[1])
        self.conv_3 = conv(inplans, planes//4, kernel_size=conv_kernels[2], padding=conv_kernels[2]//2,
                            stride=stride, groups=conv_groups[2])
        self.conv_4 = conv(inplans, planes//4, kernel_size=conv_kernels[3], padding=conv_kernels[3]//2,
                            stride=stride, groups=conv_groups[3])
        self.se = SEWeightModule(planes // 4)
        self.split_channel = planes // 4
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        batch_size = x.shape[0]
        x1 = self.conv_1(x)
        x2 = self.conv_2(x)
        x3 = self.conv_3(x)
        x4 = self.conv_4(x)

        feats = torch.cat((x1, x2, x3, x4), dim=1)
        feats = feats.view(batch_size, 4, self.split_channel, feats.shape[2], feats.shape[3])

        x1_se = self.se(x1)
        x2_se = self.se(x2)
        x3_se = self.se(x3)
        x4_se = self.se(x4)

        x_se = torch.cat((x1_se, x2_se, x3_se, x4_se), dim=1)
        attention_vectors = x_se.view(batch_size, 4, self.split_channel, 1, 1)
        attention_vectors = self.softmax(attention_vectors)
        feats_weight = feats * attention_vectors
        for i in range(4):
            x_se_weight_fp = feats_weight[:, i, :, :]
            if i == 0:
                out = x_se_weight_fp
            else:
                out = torch.cat((x_se_weight_fp, out), 1)

        return out

# class PSA(nn.Module):

#     def __init__(self, channel=512, reduction=4, S=4):
#         super().__init__()
#         self.S = S

#         self.convs = []
#         for i in range(S):
#             self.convs.append(nn.Conv2d(channel // S, channel // S, kernel_size=2 * (i + 1) + 1, padding=i + 1))

#         self.se_blocks = []
#         for i in range(S):
#             self.se_blocks.append(nn.Sequential(
#                 nn.AdaptiveAvgPool2d(1),
#                 nn.Conv2d(channel // S, channel // (S * reduction), kernel_size=1, bias=False),
#                 nn.ReLU(inplace=True),
#                 nn.Conv2d(channel // (S * reduction), channel // S, kernel_size=1, bias=False),
#                 nn.Sigmoid()
#             ))

#         self.softmax = nn.Softmax(dim=1)

#     def init_weights(self):
#         for m in self.modules():
#             if isinstance(m, nn.Conv2d):
#                 init.kaiming_normal_(m.weight, mode='fan_out')
#                 if m.bias is not None:
#                     init.constant_(m.bias, 0)
#             elif isinstance(m, nn.BatchNorm2d):
#                 init.constant_(m.weight, 1)
#                 init.constant_(m.bias, 0)
#             elif isinstance(m, nn.Linear):
#                 init.normal_(m.weight, std=0.001)
#                 if m.bias is not None:
#                     init.constant_(m.bias, 0)

#     def forward(self, x):
#         b, c, h, w = x.size()

#         # Step1:SPC module
#         SPC_out = x.view(b, self.S, c // self.S, h, w)  # bs,s,ci,h,w
#         for idx, conv in enumerate(self.convs):
#             SPC_out[:, idx, :, :, :] = conv(SPC_out[:, idx, :, :, :])

#         # Step2:SE weight
#         se_out = []
#         for idx, se in enumerate(self.se_blocks):
#             se_out.append(se(SPC_out[:, idx, :, :, :]))
#         SE_out = torch.stack(se_out, dim=1)
#         SE_out = SE_out.expand_as(SPC_out)

#         # Step3:Softmax
#         softmax_out = self.softmax(SE_out)

#         # Step4:SPA
#         PSA_out = SPC_out * softmax_out
#         PSA_out = PSA_out.view(b, -1, h, w)

#         return PSA_out
#PSA Module



#shufflenet
def channel_shuffle(x, groups):
    batchsize, num_channels, height, width = x.data.size()
    channels_per_group = num_channels // groups

    # reshape
    x = x.view(batchsize, groups,
               channels_per_group, height, width)

    x = torch.transpose(x, 1, 2).contiguous()

    # flatten
    x = x.view(batchsize, -1, height, width)

    return x


class conv_bn_relu_maxpool(nn.Module):
    def __init__(self, c1, c2):  # ch_in, ch_out
        super(conv_bn_relu_maxpool, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(c1, c2, kernel_size=3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(c2),
            nn.ReLU(inplace=True),
        )
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)

    def forward(self, x):
        return self.maxpool(self.conv(x))


class Shuffle_Block(nn.Module):
    def __init__(self, inp, oup, stride):
        super(Shuffle_Block, self).__init__()

        if not (1 <= stride <= 3):
            raise ValueError('illegal stride value')
        self.stride = stride

        branch_features = oup // 2
        assert (self.stride != 1) or (inp == branch_features << 1)

        if self.stride > 1:
            self.branch1 = nn.Sequential(
                self.depthwise_conv(inp, inp, kernel_size=3, stride=self.stride, padding=1),
                nn.BatchNorm2d(inp),
                nn.Conv2d(inp, branch_features, kernel_size=1, stride=1, padding=0, bias=False),
                nn.BatchNorm2d(branch_features),
                nn.ReLU(inplace=True),
            )

        self.branch2 = nn.Sequential(
            nn.Conv2d(inp if (self.stride > 1) else branch_features,
                      branch_features, kernel_size=1, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(branch_features),
            nn.ReLU(inplace=True),
            self.depthwise_conv(branch_features, branch_features, kernel_size=3, stride=self.stride, padding=1),
            nn.BatchNorm2d(branch_features),
            nn.Conv2d(branch_features, branch_features, kernel_size=1, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(branch_features),
            nn.ReLU(inplace=True),
        )

    @staticmethod
    def depthwise_conv(i, o, kernel_size, stride=1, padding=0, bias=False):
        return nn.Conv2d(i, o, kernel_size, stride, padding, bias=bias, groups=i)

    def forward(self, x):
        if self.stride == 1:
            x1, x2 = x.chunk(2, dim=1)  # æŒ‰ç…§ç»´åº¦1è¿›è¡Œsplit
            out = torch.cat((x1, self.branch2(x2)), dim=1)
        else:
            out = torch.cat((self.branch1(x), self.branch2(x)), dim=1)

        out = channel_shuffle(out, 2)

        return out








#MobileNet v3

class h_sigmoid(nn.Module):                           #æ”¹è¿›çš„h-swishå‡½æ•°ï¼š h-swish[X]=X*ReLU6(X+3)/6
    def __init__(self, inplace=True):                 #ReLU6æ˜¯ReLUå‡½æ•°ï¼Œæœ€å¤§å€¼ä¸º6ï¼Œæœ€å°å€¼ä¸º0
        super(h_sigmoid, self).__init__()
        self.relu = nn.ReLU6(inplace=inplace)

    def forward(self, x):
        return self.relu(x + 3) / 6

class h_swish(nn.Module):
    def __init__(self, inplace=True):
        super(h_swish, self).__init__()
        self.sigmoid = h_sigmoid(inplace=inplace)

    def forward(self, x):
        y = self.sigmoid(x)
        return x * y



# class SELayer(nn.Module):
#     def __init__(self, channel, reduction=4):
#         super(SELayer, self).__init__()
#         self.avg_pool = nn.AdaptiveAvgPool2d(1)
#         self.fc = nn.Sequential(
#                 nn.Linear(channel, channel // reduction),
#                 nn.ReLU(inplace=True),
#                 nn.Linear(channel // reduction, channel),
#                 h_sigmoid()
#         )

#     def forward(self, x):
#         b, c, _, _ = x.size()
#         y = self.avg_pool(x)
#         y = y.view(b, c)
#         y = self.fc(y).view(b, c, 1, 1)
#         return x * y

class Conv3BN(nn.Module):
    """
    This equals to
    def conv_3x3_bn(inp, oup, stride):
        return nn.Sequential(
            nn.Conv2d(inp, oup, 3, stride, 1, bias=False),
            nn.BatchNorm2d(oup),
            h_swish()
        )
    """

    def __init__(self, inp, oup, stride):
        super(Conv3BN, self).__init__()
        self.conv = nn.Conv2d(inp, oup, 3, stride, 1, bias=False)
        self.bn = nn.BatchNorm2d(oup)
        self.act = h_swish()

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

    def fuseforward(self, x):
        return self.act(self.conv(x))


class InvertedResidual(nn.Module):
    def __init__(self, inp, oup, hidden_dim, kernel_size, stride, use_se, use_hs):
        super(InvertedResidual, self).__init__()
        assert stride in [1, 2]

        self.identity = stride == 1 and inp == oup

        if inp == hidden_dim:    #é€šé“æ•°ç›¸åŒ åˆ™ä¸ºDWå·ç§¯-PWå·ç§¯
            self.conv = nn.Sequential(
                # dw
                nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, (kernel_size - 1) // 2, groups=hidden_dim,
                          bias=False),
                nn.BatchNorm2d(hidden_dim),   #BNå±‚
                h_swish() if use_hs else nn.ReLU(inplace=True),   #æ¿€æ´»å±‚
                # Squeeze-and-Excite
                SELayer(hidden_dim) if use_se else nn.Sequential(),
                # pw-linear
                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),
                nn.BatchNorm2d(oup),
            )
        else:                    #é€šé“æ•°ä¸åŒ åˆ™ä¸ºPWå·ç§¯-DWå·ç§¯-PWå·ç§¯
            self.conv = nn.Sequential(
                # pw
                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),
                nn.BatchNorm2d(hidden_dim),
                h_swish() if use_hs else nn.ReLU(inplace=True),
                # dw
                nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, (kernel_size - 1) // 2, groups=hidden_dim,
                          bias=False),
                nn.BatchNorm2d(hidden_dim),
                # Squeeze-and-Excite
                SELayer(hidden_dim) if use_se else nn.Sequential(),
                h_swish() if use_hs else nn.ReLU(inplace=True),
                # pw-linear
                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),
                nn.BatchNorm2d(oup),
            )

    def forward(self, x):
        y = self.conv(x)
        if self.identity:
            return x + y
        else:
            return y

#MobileNet v3




































class Contract(nn.Module):
    # Contract width-height into channels, i.e. x(1,64,80,80) to x(1,256,40,40)
    """ç”¨åœ¨yolo.pyçš„parse_modelæ¨¡å— ç”¨çš„ä¸å¤š
    æ”¹å˜è¾“å…¥ç‰¹å¾çš„shape å°†wå’Œhç»´åº¦(ç¼©å°)çš„æ•°æ®æ”¶ç¼©åˆ°channelç»´åº¦ä¸Š(æ”¾å¤§)
    Contract width-height into channels, i.e. x(1,64,80,80) to x(1,256,40,40)
    """
    def __init__(self, gain=2):
        super().__init__()
        self.gain = gain

    def forward(self, x):
        b, c, h, w = x.size()  # assert (h / s == 0) and (W / s == 0), 'Indivisible gain'
        s = self.gain
        x = x.view(b, c, h // s, s, w // s, s)  # x(1,64,40,2,40,2)
        x = x.permute(0, 3, 5, 1, 2, 4).contiguous()  # x(1,2,2,64,40,40)
        return x.view(b, c * s * s, h // s, w // s)  # x(1,256,40,40)


class Expand(nn.Module):
    # Expand channels into width-height, i.e. x(1,64,80,80) to x(1,16,160,160)
    """ç”¨åœ¨yolo.pyçš„parse_modelæ¨¡å—  ç”¨çš„ä¸å¤š
    æ”¹å˜è¾“å…¥ç‰¹å¾çš„shape å°†channelç»´åº¦(å˜å°)çš„æ•°æ®æ‰©å±•åˆ°Wå’ŒHç»´åº¦(å˜å¤§)
    Expand channels into width-height, i.e. x(1,64,80,80) to x(1,16,160,160)
    """
    def __init__(self, gain=2):
        super().__init__()
        self.gain = gain

    def forward(self, x):
        b, c, h, w = x.size()  # assert C / s ** 2 == 0, 'Indivisible gain'
        s = self.gain
        x = x.view(b, s, s, c // s ** 2, h, w)  # x(1,2,2,16,80,80)
        x = x.permute(0, 3, 4, 1, 5, 2).contiguous()  # x(1,16,80,2,80,2)
        return x.view(b, c // s ** 2, h * s, w * s)  # x(1,16,160,160)


class Concat(nn.Module):
    # Concatenate a list of tensors along dimension
    """åœ¨yolo.pyçš„parse_modelæ¨¡å—è°ƒç”¨
        Concatenate a list of tensors along dimension
        :params dimension: æ²¿ç€å“ªä¸ªç»´åº¦è¿›è¡Œconcat
    """
    def __init__(self, dimension=1):
        super().__init__()
        self.d = dimension

    def forward(self, x):
        #print(torch.cat(x, self.d).size())
        # print(x.size())
        # print(self.d.size())
        return torch.cat(x, self.d)



class AutoShape(nn.Module):
    # YOLOv5 input-robust model wrapper for passing cv2/np/PIL/torch inputs. Includes preprocessing, inference and NMS
    conf = 0.25  # NMS confidence threshold
    iou = 0.45  # NMS IoU threshold
    classes = None  # (optional list) filter by class
    multi_label = False  # NMS multiple labels per box
    max_det = 1000  # maximum number of detections per image

    def __init__(self, model):
        super().__init__()
        self.model = model.eval()

    def autoshape(self):
        LOGGER.info('AutoShape already enabled, skipping... ')  # model already converted to model.autoshape()
        return self

    @torch.no_grad()
    def forward(self, imgs, size=640, augment=False, profile=False):
        # Inference from various sources. For height=640, width=1280, RGB images example inputs are:
        #   file:       imgs = 'data/images/zidane.jpg'  # str or PosixPath
        #   URI:             = 'https://ultralytics.com/images/zidane.jpg'
        #   OpenCV:          = cv2.imread('image.jpg')[:,:,::-1]  # HWC BGR to RGB x(640,1280,3)
        #   PIL:             = Image.open('image.jpg') or ImageGrab.grab()  # HWC x(640,1280,3)
        #   numpy:           = np.zeros((640,1280,3))  # HWC
        #   torch:           = torch.zeros(16,3,320,640)  # BCHW (scaled to size=640, 0-1 values)
        #   multiple:        = [Image.open('image1.jpg'), Image.open('image2.jpg'), ...]  # list of images

        t = [time_sync()]
        p = next(self.model.parameters())  # for device and type
        if isinstance(imgs, torch.Tensor):  # torch
            with amp.autocast(enabled=p.device.type != 'cpu'):
                return self.model(imgs.to(p.device).type_as(p), augment, profile)  # inference

        # Pre-process
        n, imgs = (len(imgs), imgs) if isinstance(imgs, list) else (1, [imgs])  # number of images, list of images
        shape0, shape1, files = [], [], []  # image and inference shapes, filenames
        for i, im in enumerate(imgs):
            f = f'image{i}'  # filename
            if isinstance(im, (str, Path)):  # filename or uri
                im, f = Image.open(requests.get(im, stream=True).raw if str(im).startswith('http') else im), im
                im = np.asarray(exif_transpose(im))
            elif isinstance(im, Image.Image):  # PIL Image
                im, f = np.asarray(exif_transpose(im)), getattr(im, 'filename', f) or f
            files.append(Path(f).with_suffix('.jpg').name)
            if im.shape[0] < 5:  # image in CHW
                im = im.transpose((1, 2, 0))  # reverse dataloader .transpose(2, 0, 1)
            im = im[..., :3] if im.ndim == 3 else np.tile(im[..., None], 3)  # enforce 3ch input
            s = im.shape[:2]  # HWC
            shape0.append(s)  # image shape
            g = (size / max(s))  # gain
            shape1.append([y * g for y in s])
            imgs[i] = im if im.data.contiguous else np.ascontiguousarray(im)  # update
        shape1 = [make_divisible(x, int(self.stride.max())) for x in np.stack(shape1, 0).max(0)]  # inference shape
        x = [letterbox(im, new_shape=shape1, auto=False)[0] for im in imgs]  # pad
        x = np.stack(x, 0) if n > 1 else x[0][None]  # stack
        x = np.ascontiguousarray(x.transpose((0, 3, 1, 2)))  # BHWC to BCHW
        x = torch.from_numpy(x).to(p.device).type_as(p) / 255.  # uint8 to fp16/32
        t.append(time_sync())

        with amp.autocast(enabled=p.device.type != 'cpu'):
            # Inference
            y = self.model(x, augment, profile)[0]  # forward
            t.append(time_sync())

            # Post-process
            y = non_max_suppression(y, self.conf, iou_thres=self.iou, classes=self.classes,
                                    multi_label=self.multi_label, max_det=self.max_det)  # NMS
            for i in range(n):
                scale_coords(shape1, y[i][:, :4], shape0[i])

            t.append(time_sync())
            return Detections(imgs, y, files, t, self.names, x.shape)


class Detections:
    # YOLOv5 detections class for inference results
    def __init__(self, imgs, pred, files, times=None, names=None, shape=None):
        super().__init__()
        d = pred[0].device  # device
        gn = [torch.tensor([*[im.shape[i] for i in [1, 0, 1, 0]], 1., 1.], device=d) for im in imgs]  # normalizations
        self.imgs = imgs  # list of images as numpy arrays
        self.pred = pred  # list of tensors pred[0] = (xyxy, conf, cls)
        self.names = names  # class names
        self.ascii = is_ascii(names)  # names are ascii (use PIL for UTF-8)
        self.files = files  # image filenames
        self.xyxy = pred  # xyxy pixels
        self.xywh = [xyxy2xywh(x) for x in pred]  # xywh pixels
        self.xyxyn = [x / g for x, g in zip(self.xyxy, gn)]  # xyxy normalized
        self.xywhn = [x / g for x, g in zip(self.xywh, gn)]  # xywh normalized
        self.n = len(self.pred)  # number of images (batch size)
        self.t = tuple((times[i + 1] - times[i]) * 1000 / self.n for i in range(3))  # timestamps (ms)
        self.s = shape  # inference BCHW shape

    def display(self, pprint=False, show=False, save=False, crop=False, render=False, save_dir=Path('')):
        crops = []
        for i, (im, pred) in enumerate(zip(self.imgs, self.pred)):
            str = f'image {i + 1}/{len(self.pred)}: {im.shape[0]}x{im.shape[1]} '
            if pred.shape[0]:
                for c in pred[:, -1].unique():
                    n = (pred[:, -1] == c).sum()  # detections per class
                    str += f"{n} {self.names[int(c)]}{'s' * (n > 1)}, "  # add to string
                if show or save or render or crop:
                    annotator = Annotator(im, pil=not self.ascii)
                    for *box, conf, cls in reversed(pred):  # xyxy, confidence, class
                        label = f'{self.names[int(cls)]} {conf:.2f}'
                        if crop:
                            file = save_dir / 'crops' / self.names[int(cls)] / self.files[i] if save else None
                            crops.append({'box': box, 'conf': conf, 'cls': cls, 'label': label,
                                          'im': save_one_box(box, im, file=file, save=save)})
                        else:  # all others
                            annotator.box_label(box, label, color=colors(cls))
                    im = annotator.im
            else:
                str += '(no detections)'

            im = Image.fromarray(im.astype(np.uint8)) if isinstance(im, np.ndarray) else im  # from np
            if pprint:
                LOGGER.info(str.rstrip(', '))
            if show:
                im.show(self.files[i])  # show
            if save:
                f = self.files[i]
                im.save(save_dir / f)  # save
                if i == self.n - 1:
                    LOGGER.info(f"Saved {self.n} image{'s' * (self.n > 1)} to {colorstr('bold', save_dir)}")
            if render:
                self.imgs[i] = np.asarray(im)
        if crop:
            if save:
                LOGGER.info(f'Saved results to {save_dir}\n')
            return crops

    def print(self):
        self.display(pprint=True)  # print results
        LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {tuple(self.s)}' %
                    self.t)

    def show(self):
        self.display(show=True)  # show results

    def save(self, save_dir='runs/detect/exp'):
        save_dir = increment_path(save_dir, exist_ok=save_dir != 'runs/detect/exp', mkdir=True)  # increment save_dir
        self.display(save=True, save_dir=save_dir)  # save results

    def crop(self, save=True, save_dir='runs/detect/exp'):
        save_dir = increment_path(save_dir, exist_ok=save_dir != 'runs/detect/exp', mkdir=True) if save else None
        return self.display(crop=True, save=save, save_dir=save_dir)  # crop results

    def render(self):
        self.display(render=True)  # render results
        return self.imgs

    def pandas(self):
        # return detections as pandas DataFrames, i.e. print(results.pandas().xyxy[0])
        new = copy(self)  # return copy
        ca = 'xmin', 'ymin', 'xmax', 'ymax', 'confidence', 'class', 'name'  # xyxy columns
        cb = 'xcenter', 'ycenter', 'width', 'height', 'confidence', 'class', 'name'  # xywh columns
        for k, c in zip(['xyxy', 'xyxyn', 'xywh', 'xywhn'], [ca, ca, cb, cb]):
            a = [[x[:5] + [int(x[5]), self.names[int(x[5])]] for x in x.tolist()] for x in getattr(self, k)]  # update
            setattr(new, k, [pd.DataFrame(x, columns=c) for x in a])
        return new

    def tolist(self):
        # return a list of Detections objects, i.e. 'for result in results.tolist():'
        x = [Detections([self.imgs[i]], [self.pred[i]], self.names, self.s) for i in range(self.n)]
        for d in x:
            for k in ['imgs', 'pred', 'xyxy', 'xyxyn', 'xywh', 'xywhn']:
                setattr(d, k, getattr(d, k)[0])  # pop out of list
        return x

    def __len__(self):
        return self.n


class Classify(nn.Module):
    # Classification head, i.e. x(b,c1,20,20) to x(b,c2)
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1):  # ch_in, ch_out, kernel, stride, padding, groups
        super().__init__()
        self.aap = nn.AdaptiveAvgPool2d(1)  # to x(b,c1,1,1)
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g)  # to x(b,c2,1,1)
        self.flat = nn.Flatten()

    def forward(self, x):
        z = torch.cat([self.aap(y) for y in (x if isinstance(x, list) else [x])], 1)  # cat if list
        return self.flat(self.conv(z))  # flatten to x(b,c2)


#==========================================================================================================
class SELayer(nn.Module):
    # SEæ³¨æ„åŠ›æœºåˆ¶æ¨¡å—
    # https://arxiv.org/abs/1709.01507
    def __init__(self, c1, r=16):
        super(SELayer, self).__init__()
        self.avgpool = nn.AdaptiveAvgPool2d(1)
        self.l1 = nn.Linear(c1, c1 // r, bias=False)
        self.relu = nn.ReLU(inplace=True)
        self.l2 = nn.Linear(c1 // r, c1, bias=False)
        self.sig = nn.Sigmoid()

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avgpool(x).view(b, c)
        y = self.l1(y)
        y = self.relu(y)
        y = self.l2(y)
        y = self.sig(y)
        y = y.view(b, c, 1, 1)
        return x * y.expand_as(x)

class CoorAttention(nn.Module):
    """
    CA Coordinate Attention ååŒæ³¨æ„åŠ›æœºåˆ¶
    è®ºæ–‡ CVPR2021: https://arxiv.org/abs/2103.02907
    æºç : https://github.com/Andrew-Qibin/CoordAttention/blob/main/coordatt.py
    CAæ³¨æ„åŠ›æœºåˆ¶æ˜¯ä¸€ä¸ªSpatial Attention ç›¸æ¯”äºSAMçš„7x7å·ç§¯, CAå»ºç«‹äº†è¿œç¨‹ä¾èµ–
    å¯ä»¥è€ƒè™‘æŠŠSE + CAåˆèµ·æ¥ç”¨è¯•è¯•ï¼Ÿ
    """
    def __init__(self, inp, oup, reduction=32):
        super(CoorAttention, self).__init__()
        # [B, C, H, W] -> [B, C, H, 1]
        #self.pool_h = nn.AdaptiveAvgPool2d((None, 1))
        # [B, C, H, W] -> [B, C, 1, W]
        #self.pool_w = nn.AdaptiveAvgPool2d((1, None))

        mip = max(8, inp // reduction)   # å¯¹ä¸­é—´å±‚channelåšä¸€ä¸ªé™åˆ¶ ä¸å¾—å°‘äº8

        # å°†xè½´ä¿¡æ¯å’Œyè½´ä¿¡æ¯èåˆåœ¨ä¸€èµ·
        self.conv1 = nn.Conv2d(inp, mip, kernel_size=1, stride=1, padding=0)
        self.bn1 = nn.BatchNorm2d(mip)
        self.act = nn.Hardswish()  # è¿™é‡Œè‡ªå·±å¯ä»¥å®éªŒä»€ä¹ˆæ¿€æ´»å‡½æ•°æœ€ä½³ è®ºæ–‡é‡Œæ˜¯hard-swish

        self.conv_h = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)
        self.conv_w = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)

    def forward(self, x):
        identity = x

        _, _, h, w = x.size()
        # [B, C, H, W] -> [B, C, H, 1]
        pool_h = nn.AdaptiveAvgPool2d((h, 1))
        x_h = pool_h(x)   # h avg pool
        # [B, C, H, W] -> [B, C, 1, W] -> [B, C, W, 1]
        pool_w = nn.AdaptiveAvgPool2d((1, w))
        x_w = pool_w(x).permute(0, 1, 3, 2)  # w avg pool

        y = torch.cat([x_h, x_w], dim=2)  # [B, C, H+W, 1]
        y = self.conv1(y)
        y = self.bn1(y)
        y = self.act(y)

        # split  x_h: [B, C, H, 1]  x_w: [B, C, W, 1]
        x_h, x_w = torch.split(y, [h, w], dim=2)
        # [B, C, W, 1] -> [B, C, 1, W]
        x_w = x_w.permute(0, 1, 3, 2)

        a_h = self.conv_h(x_h).sigmoid()
        a_w = self.conv_w(x_w).sigmoid()

        # åŸºäºWå’ŒHæ–¹å‘åšæ³¨æ„åŠ›æœºåˆ¶ å»ºç«‹è¿œç¨‹ä¾èµ–å…³ç³»
        out = identity * a_w * a_h

        return out

#==========================================================================================================

#YOLOX head
class SiLU(nn.Module):
    @staticmethod
    def forward(x):
        return x * torch.sigmoid(x)
#åŸºæœ¬å·ç§¯ï¼ŒåŒ…æ‹¬å¤šç§æ¿€æ´»å‡½æ•°
class BaseConv(nn.Module):
    def __init__(self,
                 in_channels,
                 out_channels,
                 ksize,
                 stride,
                 groups=1,
                 bias=False,
                 act="silu"):
        super(BaseConv, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels,
                              out_channels=out_channels,
                              kernel_size=ksize,
                              stride=stride,
                              groups=groups,
                              padding=(ksize - 1) // 2,
                              bias=bias)
        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.03)
        self.act = get_activation(act, inplace=True)

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))


def get_activation(name="silu", inplace=True):
    if name == "silu":
        module = SiLU()
    elif name == "relu":
        module = nn.ReLU(inplace=inplace)
    elif name == "lrelu":
        module = nn.LeakyReLU(0.1, inplace=inplace)
    else:
        raise AttributeError("Unsupported act type: {}".format(name))
    return module



# class DWConv(nn.Module):
#     def __init__(self,
#                  in_channels,
#                  out_channels,
#                  ksize,
#                  stride=1,
#                  act="silu"):
#         super(DWConv, self).__init__()
#         self.dconv = BaseConv(in_channels=in_channels,
#                               out_channels=in_channels,
#                               ksize=ksize,
#                               stride=stride,
#                               groups=in_channels,
#                               act=act)
#         self.pconv = BaseConv(in_channels=in_channels,
#                               out_channels=out_channels,
#                               ksize=1,
#                               stride=1,
#                               groups=1,
#                               act=act)
#
#     def forward(self, x):
#         return self.pconv(self.dconv(x))


class eca_block(nn.Module):
    def __init__(self, channel, b=1, gamma=2):
        super(eca_block, self).__init__()
        kernel_size = int(abs((math.log(channel, 2) + b) / gamma))
        kernel_size = kernel_size if kernel_size % 2 else kernel_size + 1    #ä½¿å¾—å·ç§¯æ ¸ä¸ºå¥‡æ•°
        # ä¸Šé¢ç›¸å½“äºå¯¹æ¯ä¸ªä¸åŒçš„å›¾ç‰‡ï¼Œå·ç§¯æ ¸å»è‡ªé€‚åº”çš„è¿›è¡Œæ”¹å˜
        # kernel_size ä¸ºå¶æ•°
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.conv = nn.Conv1d(1, 1, kernel_size=kernel_size, padding=(kernel_size - 1) // 2, bias=False)
        # padding=(kernel_size - 1) // 2 ç›¸å½“äºpaddin=sameï¼Œå³ä¿æŒè¾“å‡ºå›¾ç‰‡å¤§å°ä¸å˜çš„æ“ä½œ
        # ä¸ºå•¥è¿™é‡Œè¿›å…¥çš„é€šé“æ•°æ˜¯1å‘¢ï¼Œæ˜¯å› ä¸ºå‰é¢æœ‰ä¸ªè‡ªé€‚åº”å±‚ï¼Œå°†å›¾ç‰‡å˜æˆäº†1*1*channelè¿™ä¸ªæ ·å­ï¼Œåœ¨ä¸‹é¢ç»è¿‡ç»´åº¦å˜æ¢ï¼Œæ­¤æ—¶å°†ç»´åº¦å˜æˆäº†b*1*cï¼Œç„¶åconv1dæ˜¯å¯¹æœ€åä¸€ç»´è¿›è¡Œå·ç§¯çš„ï¼ˆåŒç†conv2dæ˜¯å¯¹æœ€åä¸¤ç»´è¿›è¡Œå·ç§¯çš„ï¼‰å› æ­¤å°±æ˜¯å¯¹channelè¿™ä¸ªç»´åº¦è¿›è¡Œäº†ä¸€ä¸ªå·ç§¯ï¼Œæ­¤æ—¶å°±å¯ä»¥ç›¸å½“äºæŠŠä¸€ä¸ªé•¿æ–¹ä½“æ¨ªè¿‡æ¥çœ‹ï¼ˆæˆ–è€…è¯´æ¢æˆäº†channelå’Œé•¿è¿™ä¸ªé¢ï¼‰æ­¤æ—¶ç›¸å½“äºå®½ä¸ºä»¥å‰çš„é€šé“æ•°å³1.
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        y = self.avg_pool(x)
        y = self.conv(y.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)
        # y.squeeze(-1)æ˜¯å°†æœ€åä¸€ä¸ªç»´åº¦åˆ æ‰å³å®½è¿™ä¸ªç»´åº¦å°±æ²¡æœ‰äº†ï¼Œtranspose(-1, -2)æ˜¯å°†æœ€åä¸€ä¸ªå’Œå€’æ•°ç¬¬äºŒä¸ªç»´åº¦è¿›è¡Œäº’æ¢ï¼Œå³ç°åœ¨çš„ç»´åº¦å˜æˆäº†bï¼Œ1ï¼Œcè¿™ä¸‰ä¸ªç»´åº¦ï¼Œ1æ˜¯ç”±äºå‰é¢çš„è‡ªé€‚åº”å¹³å‡å±‚å˜æˆäº†1*1çš„å›¾åƒï¼Œæ‰€ä»¥é•¿åœ¨è¿™é‡Œå°±æ˜¯1ã€‚unsqueeze(-1)æ˜¯å¢åŠ æœ€åä¸€ä¸ªç»´åº¦
        y = self.sigmoid(y)
        return x * y.expand_as(x)
        # y.expand_as(x)æ˜¯å°†yçš„sizeäºxçš„sizeè¿›è¡Œä¸€ä¸ªç»Ÿä¸€ï¼Œå¯ä»¥çœ‹æˆå°†yåƒxä¸€æ ·æ‰©å±•
        
class Eca_layer(nn.Module):
    """Constructs a ECA module.

    Args:
        channel: Number of channels of the input feature map
        k_size: Adaptive selection of kernel size
    """
    def __init__(self, channel, k_size=3):
        super(Eca_layer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        # x: input features with shape [b, c, h, w]
        b, c, h, w = x.size()

        # feature descriptor on the global spatial information
        y = self.avg_pool(x)

        # Two different branches of ECA module
        y = self.conv(y.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)

        # Multi-scale information fusion
        y = self.sigmoid(y)

        return x * y.expand_as(x)

class GAMAttention(nn.Module):
    # https://paperswithcode.com/paper/global-attention-mechanism-retain-information
    def __init__(self, c1, c2, group=True, rate=4):
        super(GAMAttention, self).__init__()

        self.channel_attention = nn.Sequential(
            nn.Linear(c1, int(c1 / rate)),
            nn.ReLU(inplace=True),
            nn.Linear(int(c1 / rate), c1)
        )
        self.spatial_attention = nn.Sequential(
            nn.Conv2d(c1, c1 // rate, kernel_size=7, padding=3, groups=rate) if group else nn.Conv2d(c1, int(c1 / rate),
                                                                                                     kernel_size=7,
                                                                                                     padding=3),
            nn.BatchNorm2d(int(c1 / rate)),
            nn.ReLU(inplace=True),
            nn.Conv2d(c1 // rate, c2, kernel_size=7, padding=3, groups=rate) if group else nn.Conv2d(int(c1 / rate), c2,
                                                                                                     kernel_size=7,
                                                                                                     padding=3),
            nn.BatchNorm2d(c2)
        )

    def forward(self, x):
        b, c, h, w = x.shape
        x_permute = x.permute(0, 2, 3, 1).view(b, -1, c)
        x_att_permute = self.channel_attention(x_permute).view(b, h, w, c)
        x_channel_att = x_att_permute.permute(0, 3, 1, 2)
        x = x * x_channel_att

        x_spatial_att = self.spatial_attention(x).sigmoid()
        x_spatial_att = channel_shuffle(x_spatial_att, 4)  # last shuffle
        out = x * x_spatial_att
        return out


def channel_shuffle(x, groups=2):  ##shuffle channel
    # RESHAPE----->transpose------->Flatten
    B, C, H, W = x.size()
    out = x.view(B, groups, C // groups, H, W).permute(0, 2, 1, 3, 4).contiguous()
    out = out.view(B, C, H, W)
    return out



class E_ELAN(nn.Module):
    def __init__(self,c1,c2,flg=False):
        '''
        :param c1: è¾“å…¥é€šé“
        :param c2: è¾“å‡ºé€šé“
        :param flg: åˆ¤æ–­æ˜¯å¦ä¸ºbackboneçš„æœ€åä¸€å±‚ï¼Œå› ä¸ºè¿™é‡Œçš„è¾“å‡ºé€šé“æ•°æœ‰æ‰€æ”¹å˜
        '''

        '''
            ä¿®æ”¹ï¼šC2å˜ä¸ºäº†è¾“å‡ºé€šé“æ•°ï¼Œä¸­é—´å±‚è¾“å‡ºé€šé“æ•°ç”±c_ä»£æ›¿ã€‚
                 c_æœ‰ä¿®æ”¹ç©ºé—´ï¼Œä¸”conv2çš„kå€¼æœ‰ä¿®æ”¹ç©ºé—´ï¼Œæå¤§å½±å“äº†æ•´ä¸ªæ¨¡å‹çš„è½»é‡åŒ–ç¨‹åº¦
                 ï¼æˆ–è®¸å¯ä»¥åœ¨åœ¨æŸäº›åœ°æ–¹ä½¿ç”¨ä¸åŒçš„E_ELAN
        '''
        super(E_ELAN, self).__init__()
        # å·ç§¯ç±»å‹ä¸€
        c_ = int(c2/2)
        self.conv1 = Conv(c1, c_, k=1, s=1)
        # å·ç§¯ç±»å‹äºŒ
        self.conv2 = Conv(c_, c_, k=1, s=1)
        #catä¹‹åçš„å·ç§¯
        if flg:
            self.conv3=Conv(2*c1,c1,k=1,s=1)
        else:
            self.conv3=Conv(2*c1,c1,k=1,s=1)




    def forward(self,x):
        '''
        :param x: è¾“å…¥
        :return:
        '''
        #åˆ†æ”¯ä¸€è¾“å‡º
        output1=self.conv1(x)

        #åˆ†æ”¯äºŒè¾“å‡º
        output2_1=self.conv1(x)
        output2_2=self.conv2(output2_1)
        output2_3=self.conv2(output2_2)
        output2_4=self.conv2(output2_3)
        output2_5=self.conv2(output2_4)
        output_cat=torch.cat((output1, output2_1, output2_3, output2_5), dim=1)
        return self.conv3(output_cat)

class E_ELAN_U(nn.Module):
    def __init__(self,c1,c2,flg=False):
        '''
        :param c1: è¾“å…¥é€šé“
        :param c2: è¾“å‡ºé€šé“
        :param flg: åˆ¤æ–­æ˜¯å¦ä¸ºbackboneçš„æœ€åä¸€å±‚ï¼Œå› ä¸ºè¿™é‡Œçš„è¾“å‡ºé€šé“æ•°æœ‰æ‰€æ”¹å˜
        '''

        '''
            ä¿®æ”¹ï¼šC2å˜ä¸ºäº†è¾“å‡ºé€šé“æ•°ï¼Œä¸­é—´å±‚è¾“å‡ºé€šé“æ•°ç”±c_ä»£æ›¿ã€‚
                 c_æœ‰ä¿®æ”¹ç©ºé—´ï¼Œä¸”conv2çš„kå€¼æœ‰ä¿®æ”¹ç©ºé—´ï¼Œæå¤§å½±å“äº†æ•´ä¸ªæ¨¡å‹çš„è½»é‡åŒ–ç¨‹åº¦
                 ï¼æˆ–è®¸å¯ä»¥åœ¨åœ¨æŸäº›åœ°æ–¹ä½¿ç”¨ä¸åŒçš„E_ELAN
        '''
        super(E_ELAN, self).__init__()
        # å·ç§¯ç±»å‹ä¸€
        c_ = int(c2/2)
        self.conv1 = Conv(c1, c_, k=1, s=1)
        # å·ç§¯ç±»å‹äºŒ
        self.conv2 = Conv(c_, c_, k=1, s=1)
        #catä¹‹åçš„å·ç§¯
        if flg:
            self.conv3=Conv(2*c1,c1,k=1,s=1)
        else:
            self.conv3=Conv(2*c1,2*c1,k=1,s=1)




    def forward(self,x):
        '''
        :param x: è¾“å…¥
        :return:
        '''
        #åˆ†æ”¯ä¸€è¾“å‡º
        output1=self.conv1(x)

        #åˆ†æ”¯äºŒè¾“å‡º
        output2_1=self.conv1(x)
        output2_2=self.conv2(output2_1)
        output2_3=self.conv2(output2_2)
        output2_4=self.conv2(output2_3)
        output2_5=self.conv2(output2_4)
        output_cat=torch.cat((output1, output2_1, output2_3, output2_5), dim=1)
        return self.conv3(output_cat)


class MP(nn.Module):
    def __init__(self, k=2):
        super(MP, self).__init__()
        self.m = nn.MaxPool2d(kernel_size=k, stride=k)

    def forward(self, x):
        return self.m(x)


class MPConv(nn.Module):
    def __init__(self,c1,c2):
        '''
        :param ch_in: è¾“å¦‚é€šé“
        :param ch_out: è¿™é‡Œç»™çš„æ˜¯ä¸­é—´å±‚çš„è¾“å‡ºé€šé“
        '''
        c_ = int(c2/2)
        super(MPConv, self).__init__()
        self.conv1=nn.Sequential(
            nn.MaxPool2d(2,2),
            Conv(c1,c_,1,1),
        )
        self.conv2=nn.Sequential(
            Conv(c1,c_,1,1),
            Conv(c_,c_,3,2),
        )

    def forward(self,x):

        return torch.cat((self.conv1(x),self.conv2(x)),dim=1)

class MPConv_K(nn.Module):
    def __init__(self,c1,c2):
        '''
        :param ch_in: è¾“å¦‚é€šé“
        :param ch_out: è¿™é‡Œç»™çš„æ˜¯ä¸­é—´å±‚çš„è¾“å‡ºé€šé“
        '''
        c_ = int(c2/4)
        super(MPConv, self).__init__()
        self.conv1=nn.Sequential(
            nn.MaxPool2d(2,2),
            Conv(c1,c_,1,1),
        )
        self.conv2=nn.Sequential(
            Conv(c1,c_,1,1),
            Conv(c_,c_,3,2),
        )

    def forward(self,x):

        return torch.cat((self.conv1(x),self.conv2(x)),dim=1)


class SPPCSPC(nn.Module):
    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks
    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5, k=(5, 9, 13)):
        super(SPPCSPC, self).__init__()
        c_ = int(2 * c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(c_, c_, 3, 1)
        self.cv4 = Conv(c_, c_, 1, 1)
        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k])
        self.cv5 = Conv(4 * c_, c_, 1, 1)
        self.cv6 = Conv(c_, c_, 3, 1)
        self.cv7 = Conv(2 * c_, c2, 1, 1)

    def forward(self, x):
        x1 = self.cv4(self.cv3(self.cv1(x)))
        y1 = self.cv6(self.cv5(torch.cat([x1] + [m(x1) for m in self.m], 1)))
        y2 = self.cv2(x)
        return self.cv7(torch.cat((y1, y2), dim=1))
        
class GhostSPPCSPC(SPPCSPC):
    # CSP https://github.com/WongKinYiu/CrossStagePartialNetworks
    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5, k=(5, 9, 13)):
        super().__init__(c1, c2, n, shortcut, g, e, k)
        c_ = int(2 * c2 * e)  # hidden channels
        self.cv1 = GhostConv(c1, c_, 1, 1)
        self.cv2 = GhostConv(c1, c_, 1, 1)
        self.cv3 = GhostConv(c_, c_, 3, 1)
        self.cv4 = GhostConv(c_, c_, 1, 1)
        self.cv5 = GhostConv(4 * c_, c_, 1, 1)
        self.cv6 = GhostConv(c_, c_, 3, 1)
        self.cv7 = GhostConv(2 * c_, c2, 1, 1)



#è½»é‡åŒ–æ¨¡å—
def channel_shuffle(x, groups):
    batchsize, num_channels, height, width = x.data.size()
    channels_per_group = num_channels // groups

    # reshape
    x = x.view(batchsize, groups,
               channels_per_group, height, width)

    x = torch.transpose(x, 1, 2).contiguous()

    # flatten
    x = x.view(batchsize, -1, height, width)

    return x


class conv_bn_relu_maxpool(nn.Module):
    def __init__(self, c1, c2):  # ch_in, ch_out
        super(conv_bn_relu_maxpool, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(c1, c2, kernel_size=3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(c2),
            nn.ReLU(inplace=True),
        )
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)

    def forward(self, x):
        return self.maxpool(self.conv(x))


class Shuffle_Block(nn.Module):
    def __init__(self, inp, oup, stride):
        super(Shuffle_Block, self).__init__()

        if not (1 <= stride <= 3):
            raise ValueError('illegal stride value')
        self.stride = stride

        branch_features = oup // 2
        assert (self.stride != 1) or (inp == branch_features << 1)

        if self.stride > 1:
            self.branch1 = nn.Sequential(
                self.depthwise_conv(inp, inp, kernel_size=3, stride=self.stride, padding=1),
                nn.BatchNorm2d(inp),
                nn.Conv2d(inp, branch_features, kernel_size=1, stride=1, padding=0, bias=False),
                nn.BatchNorm2d(branch_features),
                nn.ReLU(inplace=True),
            )

        self.branch2 = nn.Sequential(
            nn.Conv2d(inp if (self.stride > 1) else branch_features,
                      branch_features, kernel_size=1, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(branch_features),
            nn.ReLU(inplace=True),
            self.depthwise_conv(branch_features, branch_features, kernel_size=3, stride=self.stride, padding=1),
            nn.BatchNorm2d(branch_features),
            nn.Conv2d(branch_features, branch_features, kernel_size=1, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(branch_features),
            nn.ReLU(inplace=True),
        )

    @staticmethod
    def depthwise_conv(i, o, kernel_size, stride=1, padding=0, bias=False):
        return nn.Conv2d(i, o, kernel_size, stride, padding, bias=bias, groups=i)

    def forward(self, x):
        if self.stride == 1:
            x1, x2 = x.chunk(2, dim=1)  # æŒ‰ç…§ç»´åº¦1è¿›è¡Œsplit
            out = torch.cat((x1, self.branch2(x2)), dim=1)
        else:
            out = torch.cat((self.branch1(x), self.branch2(x)), dim=1)

        out = channel_shuffle(out, 2)

        return out


# ---------------------------- ShuffleBlock end --------------------------------

class h_sigmoid(nn.Module):
    def __init__(self, inplace=True):
        super(h_sigmoid, self).__init__()
        self.relu = nn.ReLU6(inplace=inplace)

    def forward(self, x):
        return self.relu(x + 3) / 6


class h_swish(nn.Module):
    def __init__(self, inplace=True):
        super(h_swish, self).__init__()
        self.sigmoid = h_sigmoid(inplace=inplace)

    def forward(self, x):
        return x * self.sigmoid(x)


class Mobile_SELayer(nn.Module):
    def __init__(self, channel, reduction=4):
        super(Mobile_SELayer, self).__init__()
        # Squeezeæ“ä½œ
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        # Excitationæ“ä½œ(FC+ReLU+FC+Sigmoid)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel),
            h_sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x)
        y = y.view(b, c)
        y = self.fc(y).view(b, c, 1, 1)  # å­¦ä¹ åˆ°çš„æ¯ä¸€channelçš„æƒé‡
        return x * y


class conv_bn_hswish(nn.Module):
    """
    This equals to
    def conv_3x3_bn(inp, oup, stride):
        return nn.Sequential(
            nn.Conv2d(inp, oup, 3, stride, 1, bias=False),
            nn.BatchNorm2d(oup),
            h_swish()
        )
    """

    def __init__(self, c1, c2, stride):
        super(conv_bn_hswish, self).__init__()
        self.conv = nn.Conv2d(c1, c2, 3, stride, 1, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = h_swish()

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

    def fuseforward(self, x):
        return self.act(self.conv(x))


class MobileNet_Block(nn.Module):
    def __init__(self, inp, oup, hidden_dim, kernel_size, stride, use_se, use_hs):
        super(MobileNet_Block, self).__init__()
        assert stride in [1, 2]

        self.identity = stride == 1 and inp == oup

        # è¾“å…¥é€šé“æ•°=æ‰©å¼ é€šé“æ•° åˆ™ä¸è¿›è¡Œé€šé“æ‰©å¼ 
        if inp == hidden_dim:
            self.conv = nn.Sequential(
                # dw
                nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, (kernel_size - 1) // 2, groups=hidden_dim,
                          bias=False),
                nn.BatchNorm2d(hidden_dim),
                h_swish() if use_hs else nn.ReLU(inplace=True),
                # Squeeze-and-Excite
                Mobile_SELayer(hidden_dim) if use_se else nn.Sequential(),
                # pw-linear
                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),
                nn.BatchNorm2d(oup),
            )
        else:
            # å¦åˆ™ å…ˆè¿›è¡Œé€šé“æ‰©å¼ 
            self.conv = nn.Sequential(
                # pw
                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),
                nn.BatchNorm2d(hidden_dim),
                h_swish() if use_hs else nn.ReLU(inplace=True),
                # dw
                nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, (kernel_size - 1) // 2, groups=hidden_dim,
                          bias=False),
                nn.BatchNorm2d(hidden_dim),
                # Squeeze-and-Excite
                Mobile_SELayer(hidden_dim) if use_se else nn.Sequential(),
                h_swish() if use_hs else nn.ReLU(inplace=True),
                # pw-linear
                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),
                nn.BatchNorm2d(oup),
            )

    def forward(self, x):
        y = self.conv(x)
        if self.identity:
            return x + y
        else:
            return y


# ---------------------------- MobileBlock end ---------------------------------

class RepConv(nn.Module):
    # Represented convolution
    # https://arxiv.org/abs/2101.03697

    def __init__(self, c1, c2, k=3, s=1, p=None, g=1, act=True, deploy=False):
        super(RepConv, self).__init__()

        self.deploy = deploy
        self.groups = g
        self.in_channels = c1
        self.out_channels = c2

        assert k == 3
        assert autopad(k, p) == 1

        padding_11 = autopad(k, p) - k // 2

        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())

        if deploy:
            self.rbr_reparam = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=True)

        else:
            self.rbr_identity = (nn.BatchNorm2d(num_features=c1) if c2 == c1 and s == 1 else None)

            self.rbr_dense = nn.Sequential(
                nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False),
                nn.BatchNorm2d(num_features=c2),
            )

            self.rbr_1x1 = nn.Sequential(
                nn.Conv2d( c1, c2, 1, s, padding_11, groups=g, bias=False),
                nn.BatchNorm2d(num_features=c2),
            )

    def forward(self, inputs):
        if hasattr(self, "rbr_reparam"):
            return self.act(self.rbr_reparam(inputs))

        if self.rbr_identity is None:
            id_out = 0
        else:
            id_out = self.rbr_identity(inputs)

        return self.act(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)
    
    def get_equivalent_kernel_bias(self):
        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)
        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)
        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)
        return (
            kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid,
            bias3x3 + bias1x1 + biasid,
        )

    def _pad_1x1_to_3x3_tensor(self, kernel1x1):
        if kernel1x1 is None:
            return 0
        else:
            return nn.functional.pad(kernel1x1, [1, 1, 1, 1])

    def _fuse_bn_tensor(self, branch):
        if branch is None:
            return 0, 0
        if isinstance(branch, nn.Sequential):
            kernel = branch[0].weight
            running_mean = branch[1].running_mean
            running_var = branch[1].running_var
            gamma = branch[1].weight
            beta = branch[1].bias
            eps = branch[1].eps
        else:
            assert isinstance(branch, nn.BatchNorm2d)
            if not hasattr(self, "id_tensor"):
                input_dim = self.in_channels // self.groups
                kernel_value = np.zeros(
                    (self.in_channels, input_dim, 3, 3), dtype=np.float32
                )
                for i in range(self.in_channels):
                    kernel_value[i, i % input_dim, 1, 1] = 1
                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)
            kernel = self.id_tensor
            running_mean = branch.running_mean
            running_var = branch.running_var
            gamma = branch.weight
            beta = branch.bias
            eps = branch.eps
        std = (running_var + eps).sqrt()
        t = (gamma / std).reshape(-1, 1, 1, 1)
        return kernel * t, beta - running_mean * gamma / std

    def repvgg_convert(self):
        kernel, bias = self.get_equivalent_kernel_bias()
        return (
            kernel.detach().cpu().numpy(),
            bias.detach().cpu().numpy(),
        )

    def fuse_conv_bn(self, conv, bn):

        std = (bn.running_var + bn.eps).sqrt()
        bias = bn.bias - bn.running_mean * bn.weight / std

        t = (bn.weight / std).reshape(-1, 1, 1, 1)
        weights = conv.weight * t

        bn = nn.Identity()
        conv = nn.Conv2d(in_channels = conv.in_channels,
                              out_channels = conv.out_channels,
                              kernel_size = conv.kernel_size,
                              stride=conv.stride,
                              padding = conv.padding,
                              dilation = conv.dilation,
                              groups = conv.groups,
                              bias = True,
                              padding_mode = conv.padding_mode)

        conv.weight = torch.nn.Parameter(weights)
        conv.bias = torch.nn.Parameter(bias)
        return conv

    def fuse_repvgg_block(self):    
        if self.deploy:
            return
        print("RepConv.fuse_repvgg_block")
                
        self.rbr_dense = self.fuse_conv_bn(self.rbr_dense[0], self.rbr_dense[1])
        
        self.rbr_1x1 = self.fuse_conv_bn(self.rbr_1x1[0], self.rbr_1x1[1])
        rbr_1x1_bias = self.rbr_1x1.bias
        weight_1x1_expanded = torch.nn.functional.pad(self.rbr_1x1.weight, [1, 1, 1, 1])
        
        # Fuse self.rbr_identity
        if (isinstance(self.rbr_identity, nn.BatchNorm2d) or isinstance(self.rbr_identity, nn.modules.batchnorm.SyncBatchNorm)):
            # print(f"fuse: rbr_identity == BatchNorm2d or SyncBatchNorm")
            identity_conv_1x1 = nn.Conv2d(
                    in_channels=self.in_channels,
                    out_channels=self.out_channels,
                    kernel_size=1,
                    stride=1,
                    padding=0,
                    groups=self.groups, 
                    bias=False)
            identity_conv_1x1.weight.data = identity_conv_1x1.weight.data.to(self.rbr_1x1.weight.data.device)
            identity_conv_1x1.weight.data = identity_conv_1x1.weight.data.squeeze().squeeze()
            # print(f" identity_conv_1x1.weight = {identity_conv_1x1.weight.shape}")
            identity_conv_1x1.weight.data.fill_(0.0)
            identity_conv_1x1.weight.data.fill_diagonal_(1.0)
            identity_conv_1x1.weight.data = identity_conv_1x1.weight.data.unsqueeze(2).unsqueeze(3)
            # print(f" identity_conv_1x1.weight = {identity_conv_1x1.weight.shape}")

            identity_conv_1x1 = self.fuse_conv_bn(identity_conv_1x1, self.rbr_identity)
            bias_identity_expanded = identity_conv_1x1.bias
            weight_identity_expanded = torch.nn.functional.pad(identity_conv_1x1.weight, [1, 1, 1, 1])            
        else:
            # print(f"fuse: rbr_identity != BatchNorm2d, rbr_identity = {self.rbr_identity}")
            bias_identity_expanded = torch.nn.Parameter( torch.zeros_like(rbr_1x1_bias) )
            weight_identity_expanded = torch.nn.Parameter( torch.zeros_like(weight_1x1_expanded) )            
        

        #print(f"self.rbr_1x1.weight = {self.rbr_1x1.weight.shape}, ")
        #print(f"weight_1x1_expanded = {weight_1x1_expanded.shape}, ")
        #print(f"self.rbr_dense.weight = {self.rbr_dense.weight.shape}, ")

        self.rbr_dense.weight = torch.nn.Parameter(self.rbr_dense.weight + weight_1x1_expanded + weight_identity_expanded)
        self.rbr_dense.bias = torch.nn.Parameter(self.rbr_dense.bias + rbr_1x1_bias + bias_identity_expanded)
                
        self.rbr_reparam = self.rbr_dense
        self.deploy = True

        if self.rbr_identity is not None:
            del self.rbr_identity
            self.rbr_identity = None

        if self.rbr_1x1 is not None:
            del self.rbr_1x1
            self.rbr_1x1 = None

        if self.rbr_dense is not None:
            del self.rbr_dense
            self.rbr_dense = None

class ImplicitA(nn.Module):
    def __init__(self, channel, mean=0., std=.02):
        super(ImplicitA, self).__init__()
        self.channel = channel
        self.mean = mean
        self.std = std
        self.implicit = nn.Parameter(torch.zeros(1, channel, 1, 1))
        nn.init.normal_(self.implicit, mean=self.mean, std=self.std)

    def forward(self, x):
        return self.implicit + x
    

class ImplicitM(nn.Module):
    def __init__(self, channel, mean=1., std=.02):
        super(ImplicitM, self).__init__()
        self.channel = channel
        self.mean = mean
        self.std = std
        self.implicit = nn.Parameter(torch.ones(1, channel, 1, 1))
        nn.init.normal_(self.implicit, mean=self.mean, std=self.std)

    def forward(self, x):
        return self.implicit * x
class ReOrg(nn.Module):
    def __init__(self):
        super(ReOrg, self).__init__()

    def forward(self, x):  # x(b,c,w,h) -> y(b,4c,w/2,h/2)
        return torch.cat([x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]], 1)
class DownC(nn.Module):
    # Spatial pyramid pooling layer used in YOLOv3-SPP
    def __init__(self, c1, c2, n=1, k=2):
        super(DownC, self).__init__()
        c_ = int(c1)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2//2, 3, k)
        self.cv3 = Conv(c1, c2//2, 1, 1)
        self.mp = nn.MaxPool2d(kernel_size=k, stride=k)

    def forward(self, x):
        return torch.cat((self.cv2(self.cv1(x)), self.cv3(self.mp(x))), dim=1)

class SP(nn.Module):
    def __init__(self, k=3, s=1):
        super(SP, self).__init__()
        self.m = nn.MaxPool2d(kernel_size=k, stride=s, padding=k // 2)

    def forward(self, x):
        return self.m(x)

class CBAM(nn.Module):
    def __init__(self, c1,c2):
        super(CBAM, self).__init__()
        self.channel_attention = ChannelAttention(c1)
        self.spatial_attention = SpatialAttention()

    def forward(self, x):
        out = self.channel_attention(x) * x
        out = self.spatial_attention(out) * out
        return out
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        """
        :params: in_planes è¾“å…¥æ¨¡å—çš„feature mapçš„channel
        :params: ratio é™ç»´/å‡ç»´å› å­
        é€šé“æ³¨æ„åŠ›åˆ™æ˜¯å°†ä¸€ä¸ªé€šé“å†…çš„ä¿¡æ¯ç›´æ¥è¿›è¡Œå…¨å±€å¤„ç†ï¼Œå®¹æ˜“å¿½ç•¥é€šé“å†…çš„ä¿¡æ¯äº¤äº’
        """
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)  # å¹³å‡æ± åŒ–ï¼Œæ˜¯å–æ•´ä¸ªchannelæ‰€æœ‰å…ƒç´ çš„å‡å€¼ [3,5,5] => [3,1,1]
        self.max_pool = nn.AdaptiveMaxPool2d(1)  # æœ€å¤§æ± åŒ–ï¼Œæ˜¯å–æ•´ä¸ªchannelæ‰€æœ‰å…ƒç´ çš„æœ€å¤§å€¼[3,5,5] => [3,1,1]

        # shared MLP
        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)

        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))
        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))
        out = avg_out + max_out
        return self.sigmoid(out)
class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        """å¯¹ç©ºé—´æ³¨æ„åŠ›æ¥è¯´ï¼Œç”±äºå°†æ¯ä¸ªé€šé“ä¸­çš„ç‰¹å¾éƒ½åšåŒç­‰å¤„ç†ï¼Œå®¹æ˜“å¿½ç•¥é€šé“é—´çš„ä¿¡æ¯äº¤äº’"""
        super(SpatialAttention, self).__init__()

        # è¿™é‡Œè¦ä¿æŒå·ç§¯åçš„featureå°ºåº¦ä¸å˜ï¼Œå¿…é¡»è¦padding=kernel_size//2
        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):                               # è¾“å…¥x = [b, c, 56, 56]
        avg_out = torch.mean(x, dim=1, keepdim=True)    # avg_out = [b, 1, 56, 56]  æ±‚xçš„æ¯ä¸ªåƒç´ åœ¨æ‰€æœ‰channelç›¸åŒä½ç½®ä¸Šçš„å¹³å‡å€¼
        max_out, _ = torch.max(x, dim=1, keepdim=True)  # max_out = [b, 1, 56, 56]  æ±‚xçš„æ¯ä¸ªåƒç´ åœ¨æ‰€æœ‰channelç›¸åŒä½ç½®ä¸Šçš„æœ€å¤§å€¼
        x = torch.cat([avg_out, max_out], dim=1)        # x = [b, 2, 56, 56]  concatæ“ä½œ
        x = self.conv1(x)                               # x = [b, 1, 56, 56]  å·ç§¯æ“ä½œï¼Œèåˆavgå’Œmaxçš„ä¿¡æ¯ï¼Œå…¨æ–¹é¢è€ƒè™‘
        return self.sigmoid(x)



######################  Idetect  IAuxDetect  ####     start ###############################
 
class ImplicitA(nn.Module):
    def __init__(self, channel, mean=0., std=.02):
        super(ImplicitA, self).__init__()
        self.channel = channel
        self.mean = mean
        self.std = std
        self.implicit = nn.Parameter(torch.zeros(1, channel, 1, 1))
        nn.init.normal_(self.implicit, mean=self.mean, std=self.std)
 
    def forward(self, x):
        return self.implicit + x
 
 
class ImplicitM(nn.Module):
    def __init__(self, channel, mean=0., std=.02):
        super(ImplicitM, self).__init__()
        self.channel = channel
        self.mean = mean
        self.std = std
        self.implicit = nn.Parameter(torch.ones(1, channel, 1, 1))
        nn.init.normal_(self.implicit, mean=self.mean, std=self.std)
 
    def forward(self, x):
        return self.implicit * x
 
######################  Idetect  IAuxDetect  ####     end ###############################


#====MobileOne====#
import copy as copy2   # ä¸ºé˜²æ­¢ä¸commonåŸæ¥å¼•å…¥çš„copyå†²çª, for mobileone reparameterize
from typing import Optional, List, Tuple

class SEBlock(nn.Module):
    """ Squeeze and Excite module.
        https://arxiv.org/pdf/1709.01507.pdf
    """

    def __init__(self, in_channels: int, rd_ratio: float = 0.0625) -> None:
        """ Construct a Squeeze and Excite Module.
        :param in_channels: Number of input channels.
        :param rd_ratio: Input channel reduction ratio.
        """
        super(SEBlock, self).__init__()
        self.reduce = nn.Conv2d(in_channels=in_channels,out_channels=int(in_channels * rd_ratio), kernel_size=1, stride=1, bias=True)
        self.expand = nn.Conv2d(in_channels=int(in_channels * rd_ratio),out_channels=in_channels, kernel_size=1, stride=1, bias=True)

    def forward(self, inputs: torch.Tensor) -> torch.Tensor:
        """ Apply forward pass. """
        b, c, h, w = inputs.size()
        x = F.avg_pool2d(inputs, kernel_size=[h, w])
        x = self.reduce(x)
        x = F.relu(x)
        x = self.expand(x)
        x = torch.sigmoid(x)
        x = x.view(-1, c, 1, 1)
        return inputs * x
        
# def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):
#     result = nn.Sequential()
#     result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,
#                                                   kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))
#     result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))
#     return 

class DepthWiseConv(nn.Module):
    def __init__(self, inc, kernel_size, stride=1):
        super().__init__()
        padding = 1
        if kernel_size == 1:
            padding = 0
        self.conv = nn.Sequential(
            nn.Conv2d(inc, inc, kernel_size, stride, padding, groups=inc, bias=False,),
            nn.BatchNorm2d(inc),
        )
        #self.conv = conv_bn(inc, inc,kernel_size, stride, padding, inc)

    def forward(self, x):
        y = self.conv(x)
        return y
    

class PointWiseConv(nn.Module):
    def __init__(self, inc, outc):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(inc, outc, 1, 1, 0, bias=False),
            nn.BatchNorm2d(outc),
        )
        #self.conv = conv_bn(inc, outc, 1, 1, 0)
    def forward(self, x):
        y = self.conv(x)
        return y



class MobileOneBlock(nn.Module):

    def __init__(self, in_channels, out_channels, k,
                 stride=1, dilation=1, padding_mode='zeros', deploy=False, use_se=False):
        super(MobileOneBlock, self).__init__()
        self.deploy = deploy
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.deploy = deploy
        kernel_size = 3
        padding = 1
        assert kernel_size == 3
        assert padding == 1
        self.k = k
        padding_11 = padding - kernel_size // 2

        self.nonlinearity = nn.ReLU()

        if use_se:
            # self.se = SEBlock(out_channels, internal_neurons=out_channels // 16)
            ...
        else:
            self.se = nn.Identity()

        if deploy:
            self.dw_reparam = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size, stride=stride,
                                      padding=padding, dilation=dilation, groups=in_channels, bias=True, padding_mode=padding_mode)
            self.pw_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, bias=True)

        else:
            # self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None
            # self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)
            # self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)
            # print('RepVGG Block, identity = ', self.rbr_identity)
            self.dw_bn_layer = nn.BatchNorm2d(in_channels) if out_channels == in_channels and stride == 1 else None
            for k_idx in range(k):
                setattr(self, f'dw_3x3_{k_idx}', 
                    DepthWiseConv(in_channels, 3, stride=stride)
                )
            self.dw_1x1 = DepthWiseConv(in_channels, 1, stride=stride)

            self.pw_bn_layer = nn.BatchNorm2d(in_channels) if out_channels == in_channels and stride == 1 else None
            for k_idx in range(k):
                setattr(self, f'pw_1x1_{k_idx}', 
                    PointWiseConv(in_channels, out_channels)
                )

    def forward(self, inputs):
        if self.deploy:
            x = self.dw_reparam(inputs)
            x = self.nonlinearity(x)
            x = self.pw_reparam(x)
            x = self.nonlinearity(x)
            return x

        if self.dw_bn_layer is None:
            id_out = 0
        else:
            id_out = self.dw_bn_layer(inputs)
        
        x_conv_3x3 = []
        for k_idx in range(self.k):
            x = getattr(self, f'dw_3x3_{k_idx}')(inputs)
            x_conv_3x3.append(x)
        x_conv_1x1 = self.dw_1x1(inputs)
        # print(x_conv_1x1.shape, x_conv_3x3[0].shape)
        # print(x_conv_1x1.shape)
        # print(id_out)
        x = id_out + x_conv_1x1 + sum(x_conv_3x3)
        x = self.nonlinearity(self.se(x))

         # 1x1 conv
        if self.pw_bn_layer is None:
            id_out = 0
        else:
            id_out = self.pw_bn_layer(x)
        x_conv_1x1 = []
        for k_idx in range(self.k):
            x_conv_1x1.append(getattr(self, f'pw_1x1_{k_idx}')(x))
        x = id_out + sum(x_conv_1x1)
        x = self.nonlinearity(x)
        return x
        
class MobileOne(nn.Module):
    # MobileOne
    def __init__(self, in_channels, out_channels, n, k,
                 stride=1, dilation=1, padding_mode='zeros', deploy=False, use_se=False):
        super().__init__()
        self.m = nn.Sequential(*[MobileOneBlock(in_channels, out_channels, k, stride, deploy) for _ in range(n)])

    def forward(self, x):
        x = self.m(x)
        return x



class SKAttention(nn.Module):
    
    def __init__(self, channel=512,kernels=[1,3,5,7],reduction=16,group=1,L=32):
        super().__init__()
        self.d=max(L,channel//reduction)
        self.convs=nn.ModuleList([])
        for k in kernels:
            self.convs.append(
                nn.Sequential(collections.OrderedDict([
                    ('conv',nn.Conv2d(channel,channel,kernel_size=k,padding=k//2,groups=group)),
                    ('bn',nn.BatchNorm2d(channel)),
                    ('relu',nn.ReLU())
                ]))
            )
        self.fc=nn.Linear(channel,self.d)
        self.fcs=nn.ModuleList([])
        for i in range(len(kernels)):
            self.fcs.append(nn.Linear(self.d,channel))
        self.softmax=nn.Softmax(dim=0)

    def forward(self, x):
        bs, c, _, _ = x.size()
        conv_outs=[]
        ### split
        for conv in self.convs:
            conv_outs.append(conv(x))
        feats=torch.stack(conv_outs,0)#k,bs,channel,h,w

        ### fuse
        U=sum(conv_outs) #bs,c,h,w

        ### reduction channel
        S=U.mean(-1).mean(-1) #bs,c
        Z=self.fc(S) #bs,d

        ### calculate attention weight
        weights=[]
        for fc in self.fcs:
            weight=fc(Z)
            weights.append(weight.view(bs,c,1,1)) #bs,channel
        attention_weughts=torch.stack(weights,0)#k,bs,channel,1,1
        attention_weughts=self.softmax(attention_weughts)#k,bs,channel,1,1

        ### fuse
        V=(attention_weughts*feats).sum(0)
        return V


# import torch.nn as nn
# import numpy as np
# import torch

# def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):
#     result = nn.Sequential()
#     result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,
#                                                   kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))
#     result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))
#     return result

# class DepthWiseConv(nn.Module):
#     def __init__(self, inc, kernel_size, stride=1):
#         super().__init__()
#         padding = 1
#         if kernel_size == 1:
#             padding = 0
#         self.conv = conv_bn(inc, inc,kernel_size, stride, padding, inc)

#     def forward(self, x):
#         return self.conv(x)

# # https://arxiv.org/abs/2206.04040
# # unofficial: https://github.com/shoutOutYangJie/MobileOne
# class PointWiseConv(nn.Module):
#     def __init__(self, inc, outc):
#         super().__init__()
#         self.conv = conv_bn(inc, outc, 1, 1, 0)
#     def forward(self, x):
#         return self.conv(x)

# class MobileOneBlock(nn.Module):
#     def __init__(self, in_channels, out_channels, k,
#                  stride=1, dilation=1, padding_mode='zeros', deploy=False, use_se=False):
#         super(MobileOneBlock, self).__init__()
#         self.deploy = deploy
#         self.in_channels = in_channels
#         self.out_channels = out_channels
#         self.deploy = deploy
#         kernel_size = 3
#         padding = 1
#         assert kernel_size == 3
#         assert padding == 1
#         self.k = k
#         padding_11 = padding - kernel_size // 2
#         self.nonlinearity = nn.ReLU()

#         if use_se:
#             # self.se = SEBlock(out_channels, internal_neurons=out_channels // 16)
#             ...
#         else:
#             self.se = nn.Identity()

#         if deploy:
#             self.dw_reparam = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size, stride=stride,
#                                       padding=padding, dilation=dilation, groups=in_channels, bias=True, padding_mode=padding_mode)
#             self.deploy_bn = nn.BatchNorm2d(in_channels)
#             self.pw_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, bias=True)

#         else:
#             self.dw_bn_layer = nn.BatchNorm2d(in_channels) if out_channels == in_channels and stride == 1 else None
#             for k_idx in range(k):
#                 setattr(self, f'dw_3x3_{k_idx}', 
#                     DepthWiseConv(in_channels, 3, stride=stride)
#                 )
#             self.dw_1x1 = DepthWiseConv(in_channels, 1, stride=stride)

#             self.pw_bn_layer = nn.BatchNorm2d(in_channels) if out_channels == in_channels and stride == 1 else None
#             for k_idx in range(k):
#                 setattr(self, f'pw_1x1_{k_idx}', 
#                     PointWiseConv(in_channels, out_channels)
#                 )

#     def forward(self, inputs):
#         if self.deploy:
#             x = self.dw_reparam(inputs)
#             x = self.deploy_bn(x)
#             x = self.nonlinearity(x)
#             x = self.pw_reparam(x)
#             x = self.deploy_bn(x)
#             x = self.nonlinearity(x)
#             return x

#         if self.dw_bn_layer is None:
#             id_out = 0
#         else:
#             id_out = self.dw_bn_layer(inputs)
        
#         x_conv_3x3 = []
#         for k_idx in range(self.k):
#             x = getattr(self, f'dw_3x3_{k_idx}')(inputs)
#             x_conv_3x3.append(x)
#         x_conv_1x1 = self.dw_1x1(inputs)

#         x = id_out + x_conv_1x1 + sum(x_conv_3x3)
#         x = self.nonlinearity(self.se(x))

#          # 1x1 conv # https://github.com/iscyy/yoloair
#         if self.pw_bn_layer is None:
#             id_out = 0
#         else:
#             id_out = self.pw_bn_layer(x)
#         x_conv_1x1 = []
#         for k_idx in range(self.k):
#             x_conv_1x1.append(getattr(self, f'pw_1x1_{k_idx}')(x))
#         x = id_out + sum(x_conv_1x1)
#         x = self.nonlinearity(x)
#         return x


# ------------------------------efficientnetv2--------------------------------------

class stem(nn.Module):
    def __init__(self, c1, c2, kernel_size=3, stride=1, groups=1):
        super().__init__()
        # kernel_sizeä¸º3æ—¶ï¼Œpadding ä¸º1ï¼Œkernelä¸º1æ—¶ï¼Œpaddingä¸º0
        padding = (kernel_size - 1) // 2
        # ç”±äºè¦åŠ bnå±‚ï¼Œæ‰€ä»¥ä¸åŠ åç½®
        self.conv = nn.Conv2d(c1, c2, kernel_size, stride, padding=padding, groups=groups, bias=False)
        self.bn = nn.BatchNorm2d(c2, eps=1e-3, momentum=0.1)
        self.act = nn.SiLU(inplace=True)

    def forward(self, x):
        # print(x.shape)
        x = self.conv(x)
        x = self.bn(x)
        x = self.act(x)
        return x


def drop_path(x, drop_prob: float = 0., training: bool = False):
    if drop_prob == 0. or not training:
        return x
    keep_prob = 1 - drop_prob
    shape = (x.shape[0],) + (1,) * (x.ndim - 1)
    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)
    random_tensor.floor_()  # binarize

    output = x.div(keep_prob) * random_tensor
    return output


class DropPath(nn.Module):
    def __init__(self, drop_prob=None):
        super(DropPath, self).__init__()
        self.drop_prob = drop_prob

    def forward(self, x):
        return drop_path(x, self.drop_prob, self.training)


class SqueezeExcite_efficientv2(nn.Module):
    def __init__(self, c1, c2, se_ratio=0.25, act_layer=nn.ReLU):
        super().__init__()
        self.gate_fn = nn.Sigmoid()
        reduced_chs = int(c1 * se_ratio)
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.conv_reduce = nn.Conv2d(c1, reduced_chs, 1, bias=True)
        self.act1 = act_layer(inplace=True)
        self.conv_expand = nn.Conv2d(reduced_chs, c2, 1, bias=True)

    def forward(self, x):
        # å…ˆå…¨å±€å¹³å‡æ± åŒ–
        x_se = self.avg_pool(x)
        # å†å…¨è¿æ¥ï¼ˆè¿™é‡Œæ˜¯ç”¨çš„1x1å·ç§¯ï¼Œæ•ˆæœä¸å…¨è¿æ¥ä¸€æ ·ï¼Œä½†é€Ÿåº¦å¿«ï¼‰
        x_se = self.conv_reduce(x_se)
        # ReLUæ¿€æ´»
        x_se = self.act1(x_se)
        # å†å…¨è¿æ¥
        x_se = self.conv_expand(x_se)
        # sigmoidæ¿€æ´»
        x_se = self.gate_fn(x_se)
        # å°†x_se ç»´åº¦æ‰©å±•ä¸ºå’Œxä¸€æ ·çš„ç»´åº¦
        x = x * (x_se.expand_as(x))
        return x

# Fused-MBConv å°† MBConv ä¸­çš„ depthwise conv3Ã—3 å’Œæ‰©å±• conv1Ã—1 æ›¿æ¢ä¸ºå•ä¸ªå¸¸è§„ conv3Ã—3ã€‚
class FusedMBConv(nn.Module):
    def __init__(self, c1, c2, k=3, s=1, expansion=1, se_ration=0, dropout_rate=0.2, drop_connect_rate=0.2):
        super().__init__()
        # shorcut æ˜¯æŒ‡åˆ°æ®‹å·®ç»“æ„ expansionæ˜¯ä¸ºäº†å…ˆå‡ç»´ï¼Œå†å·ç§¯ï¼Œå†é™ç»´ï¼Œå†æ®‹å·®
        self.has_shortcut = (s == 1 and c1 == c2)  # åªè¦æ˜¯æ­¥é•¿ä¸º1å¹¶ä¸”è¾“å…¥è¾“å‡ºç‰¹å¾å›¾å¤§å°ç›¸ç­‰ï¼Œå°±æ˜¯True å°±å¯ä»¥ä½¿ç”¨åˆ°æ®‹å·®ç»“æ„è¿æ¥
        self.has_expansion = expansion != 1  # expansion==1 ä¸ºfalse expansionä¸ä¸º1æ—¶ï¼Œè¾“å‡ºç‰¹å¾å›¾ç»´åº¦å°±ä¸ºexpansion*c1ï¼Œkå€çš„c1,æ‰©å±•ç»´åº¦
        expanded_c = c1 * expansion

        if self.has_expansion:
            self.expansion_conv = stem(c1, expanded_c, kernel_size=k, stride=s)
            self.project_conv = stem(expanded_c, c2, kernel_size=1, stride=1)
        else:
            self.project_conv = stem(c1, c2, kernel_size=k, stride=s)

        self.drop_connect_rate = drop_connect_rate
        if self.has_shortcut and drop_connect_rate > 0:
            self.dropout = DropPath(drop_connect_rate)

    def forward(self, x):
        if self.has_expansion:
            result = self.expansion_conv(x)
            result = self.project_conv(result)
        else:
            result = self.project_conv(x)
        if self.has_shortcut:
            if self.drop_connect_rate > 0:
                result = self.dropout(result)
            result += x

        return result


class MBConv(nn.Module):
    def __init__(self, c1, c2, k=3, s=1, expansion=1, se_ration=0, dropout_rate=0.2, drop_connect_rate=0.2):
        super().__init__()
        self.has_shortcut = (s == 1 and c1 == c2)
        expanded_c = c1 * expansion
        self.expansion_conv = stem(c1, expanded_c, kernel_size=1, stride=1)
        self.dw_conv = stem(expanded_c, expanded_c, kernel_size=k, stride=s, groups=expanded_c)
        self.se = SqueezeExcite_efficientv2(expanded_c, expanded_c, se_ration) if se_ration > 0 else nn.Identity()
        self.project_conv = stem(expanded_c, c2, kernel_size=1, stride=1)
        self.drop_connect_rate = drop_connect_rate
        if self.has_shortcut and drop_connect_rate > 0:
            self.dropout = DropPath(drop_connect_rate)

    def forward(self, x):
        # å…ˆç”¨1x1çš„å·ç§¯å¢åŠ å‡ç»´
        result = self.expansion_conv(x)
        # å†ç”¨ä¸€èˆ¬çš„å·ç§¯ç‰¹å¾æå–
        result = self.dw_conv(result)
        # æ·»åŠ seæ¨¡å—
        result = self.se(result)
        # å†ç”¨1x1çš„å·ç§¯é™ç»´
        result = self.project_conv(result)
        # å¦‚æœä½¿ç”¨shortcutè¿æ¥ï¼Œåˆ™åŠ å…¥dropoutæ“ä½œ
        if self.has_shortcut:
            if self.drop_connect_rate > 0:
                result = self.dropout(result)
            # shortcutå°±æ˜¯åˆ°æ®‹å·®ç»“æ„ï¼Œè¾“å…¥è¾“å…¥çš„channelå¤§å°ç›¸ç­‰ï¼Œè¿™æ ·å°±èƒ½ç›¸åŠ äº†
            result += x

        return result

# ------------------------------efficientnetv2--------------------------------------

