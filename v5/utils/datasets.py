# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
Dataloaders and dataset utils
"""

import glob
import hashlib
import json
import logging
import os
import random
import shutil
import time
from itertools import repeat
from multiprocessing.pool import ThreadPool, Pool
from pathlib import Path
from threading import Thread

import cv2
import numpy as np
import torch
import torch.nn.functional as F
import yaml
from PIL import Image, ExifTags
from torch.utils.data import Dataset
from tqdm import tqdm

from utils.augmentations import Albumentations, augment_hsv, copy_paste, letterbox, mixup, random_perspective
from utils.general import check_dataset, check_requirements, check_yaml, clean_str, segments2boxes, \
    xywh2xyxy, xywhn2xyxy, xyxy2xywhn, xyn2xy
from utils.torch_utils import torch_distributed_zero_first

# Parameters
HELP_URL = 'https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data'
IMG_FORMATS = ['bmp', 'jpg', 'jpeg', 'png', 'tif', 'tiff', 'dng', 'webp', 'mpo']  # acceptable image suffixes
VID_FORMATS = ['mov', 'avi', 'mp4', 'mpg', 'mpeg', 'm4v', 'wmv', 'mkv']  # acceptable video suffixes
NUM_THREADS = min(8, os.cpu_count())  # number of multiprocessing threads

# ç›¸æœºè®¾ç½®
# Get orientation exif tag
# ä¸“é—¨ä¸ºæ•°ç ç›¸æœºçš„ç…§ç‰‡è€Œè®¾å®š  å¯ä»¥è®°å½•æ•°ç ç…§ç‰‡çš„å±æ€§ä¿¡æ¯å’Œæ‹æ‘„æ•°æ®
for orientation in ExifTags.TAGS.keys():
    if ExifTags.TAGS[orientation] == 'Orientation':
        break


def get_hash(paths):
    # è¿”å›æ–‡ä»¶åˆ—è¡¨çš„hashå€¼
    # Returns a single hash value of a list of paths (files or dirs)
    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes
    h = hashlib.md5(str(size).encode())  # hash sizes
    h.update(''.join(paths).encode())  # hash paths
    return h.hexdigest()  # return hash


def exif_size(img):
    # è·å–æ•°ç ç›¸æœºçš„å›¾ç‰‡å®½é«˜ä¿¡æ¯  å¹¶ä¸”åˆ¤æ–­æ˜¯å¦éœ€è¦æ—‹è½¬ï¼ˆæ•°ç ç›¸æœºå¯ä»¥å¤šè§’åº¦æ‹æ‘„ï¼‰
    # Returns exif-corrected PIL size
    s = img.size  # (width, height)
    try:
        rotation = dict(img._getexif().items())[orientation]
        if rotation == 6:  # rotation 270
            s = (s[1], s[0])
        elif rotation == 8:  # rotation 90
            s = (s[1], s[0])
    except:
        pass

    return s


def exif_transpose(image):
    """
    Transpose a PIL image accordingly if it has an EXIF Orientation tag.
    From https://github.com/python-pillow/Pillow/blob/master/src/PIL/ImageOps.py

    :param image: The image to transpose.
    :return: An image.
    """
    exif = image.getexif()
    orientation = exif.get(0x0112, 1)  # default 1
    if orientation > 1:
        method = {2: Image.FLIP_LEFT_RIGHT,
                  3: Image.ROTATE_180,
                  4: Image.FLIP_TOP_BOTTOM,
                  5: Image.TRANSPOSE,
                  6: Image.ROTATE_270,
                  7: Image.TRANSVERSE,
                  8: Image.ROTATE_90,
                  }.get(orientation)
        if method is not None:
            image = image.transpose(method)
            del exif[0x0112]
            image.info["exif"] = exif.tobytes()
    return image


def create_dataloader(path, imgsz, batch_size, stride, single_cls=False, hyp=None, augment=False, cache=False, pad=0.0,
                      rect=False, rank=-1, workers=8, image_weights=False, quad=False, prefix=''):
    """åœ¨train.pyä¸­è¢«è°ƒç”¨ï¼Œç”¨äºç”ŸæˆTrainloader, datasetï¼Œtestloader
    è‡ªå®šä¹‰dataloaderå‡½æ•°: è°ƒç”¨LoadImagesAndLabelsè·å–æ•°æ®é›†(åŒ…æ‹¬æ•°æ®å¢å¼º) + è°ƒç”¨åˆ†å¸ƒå¼é‡‡æ ·å™¨DistributedSampler +
                        è‡ªå®šä¹‰InfiniteDataLoader è¿›è¡Œæ°¸ä¹…æŒç»­çš„é‡‡æ ·æ•°æ®
    :param path: å›¾ç‰‡æ•°æ®åŠ è½½è·¯å¾„ train/test  å¦‚: ../datasets/VOC/images/train2007
    :param imgsz: train/testå›¾ç‰‡å°ºå¯¸ï¼ˆæ•°æ®å¢å¼ºåå¤§å°ï¼‰ 640
    :param batch_size: batch size å¤§å° 8/16/32
    :param stride: æ¨¡å‹æœ€å¤§stride=32   [32 16 8]
    :param single_cls: æ•°æ®é›†æ˜¯å¦æ˜¯å•ç±»åˆ« é»˜è®¤False
    :param hyp: è¶…å‚åˆ—è¡¨dict ç½‘ç»œè®­ç»ƒæ—¶çš„ä¸€äº›è¶…å‚æ•°ï¼ŒåŒ…æ‹¬å­¦ä¹ ç‡ç­‰ï¼Œè¿™é‡Œä¸»è¦ç”¨åˆ°é‡Œé¢ä¸€äº›å…³äºæ•°æ®å¢å¼º(æ—‹è½¬ã€å¹³ç§»ç­‰)çš„ç³»æ•°
    :param augment: æ˜¯å¦è¦è¿›è¡Œæ•°æ®å¢å¼º  True
    :param cache: æ˜¯å¦cache_images False
    :param pad: è®¾ç½®çŸ©å½¢è®­ç»ƒçš„shapeæ—¶è¿›è¡Œçš„å¡«å…… é»˜è®¤0.0
    :param rect: æ˜¯å¦å¼€å¯çŸ©å½¢train/test  é»˜è®¤è®­ç»ƒé›†å…³é—­ éªŒè¯é›†å¼€å¯
    :param rank:  å¤šå¡è®­ç»ƒæ—¶çš„è¿›ç¨‹ç¼–å· rankä¸ºè¿›ç¨‹ç¼–å·  -1ä¸”gpu=1æ—¶ä¸è¿›è¡Œåˆ†å¸ƒå¼  -1ä¸”å¤šå—gpuä½¿ç”¨DataParallelæ¨¡å¼  é»˜è®¤-1
    :param workers: dataloaderçš„numworks åŠ è½½æ•°æ®æ—¶çš„cpuè¿›ç¨‹æ•°
    :param image_weights: è®­ç»ƒæ—¶æ˜¯å¦æ ¹æ®å›¾ç‰‡æ ·æœ¬çœŸå®æ¡†åˆ†å¸ƒæƒé‡æ¥é€‰æ‹©å›¾ç‰‡  é»˜è®¤False
    :param quad: dataloaderå–æ•°æ®æ—¶, æ˜¯å¦ä½¿ç”¨collate_fn4ä»£æ›¿collate_fn  é»˜è®¤False
    :param prefix: æ˜¾ç¤ºä¿¡æ¯   ä¸€ä¸ªæ ‡å¿—ï¼Œå¤šä¸ºtrain/valï¼Œå¤„ç†æ ‡ç­¾æ—¶ä¿å­˜cacheæ–‡ä»¶ä¼šç”¨åˆ°
    """
    # Make sure only the first process in DDP process the dataset first, and the following others can use the cache
    # ä¸»è¿›ç¨‹å®ç°æ•°æ®çš„é¢„è¯»å–å¹¶ç¼“å­˜ï¼Œç„¶åå…¶å®ƒå­è¿›ç¨‹åˆ™ä»ç¼“å­˜ä¸­è¯»å–æ•°æ®å¹¶è¿›è¡Œä¸€ç³»åˆ—è¿ç®—ã€‚
    # ä¸ºäº†å®Œæˆæ•°æ®çš„æ­£å¸¸åŒæ­¥, yolov5åŸºäºtorch.distributed.barrier()å‡½æ•°å®ç°äº†ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    with torch_distributed_zero_first(rank):
        # è½½å…¥æ–‡ä»¶æ•°æ®(å¢å¼ºæ•°æ®é›†)
        dataset = LoadImagesAndLabels(path, imgsz, batch_size,
                                      augment=augment,  # augment images
                                      hyp=hyp,  # augmentation hyperparameters
                                      rect=rect,  # rectangular training
                                      cache_images=cache,
                                      single_cls=single_cls,
                                      stride=int(stride),
                                      pad=pad,
                                      image_weights=image_weights,
                                      prefix=prefix)

    batch_size = min(batch_size, len(dataset))
    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, workers])  # number of workers
    # åˆ†å¸ƒå¼é‡‡æ ·å™¨DistributedSampler
    sampler = torch.utils.data.distributed.DistributedSampler(dataset) if rank != -1 else None
    # ä½¿ç”¨InfiniteDataLoaderå’Œ_RepeatSampleræ¥å¯¹DataLoaderè¿›è¡Œå°è£…, ä»£æ›¿åŸå…ˆçš„DataLoader, èƒ½å¤Ÿæ°¸ä¹…æŒç»­çš„é‡‡æ ·æ•°æ®
    loader = torch.utils.data.DataLoader if image_weights else InfiniteDataLoader
    # Use torch.utils.data.DataLoader() if dataset.properties will update during training else InfiniteDataLoader()
    dataloader = loader(dataset,
                        batch_size=batch_size,
                        num_workers=nw,
                        sampler=sampler,
                        pin_memory=True,
                        collate_fn=LoadImagesAndLabels.collate_fn4 if quad else LoadImagesAndLabels.collate_fn)
    return dataloader, dataset


class InfiniteDataLoader(torch.utils.data.dataloader.DataLoader):
    """ Dataloader that reuses workers

    å½“image_weights=Falseæ—¶å°±ä¼šè°ƒç”¨è¿™ä¸¤ä¸ªå‡½æ•° è¿›è¡Œè‡ªå®šä¹‰DataLoader
    https://github.com/ultralytics/yolov5/pull/876
    ä½¿ç”¨InfiniteDataLoaderå’Œ_RepeatSampleræ¥å¯¹DataLoaderè¿›è¡Œå°è£…, ä»£æ›¿åŸå…ˆçš„DataLoader, èƒ½å¤Ÿæ°¸ä¹…æŒç»­çš„é‡‡æ ·æ•°æ®

    Uses same syntax as vanilla DataLoader
    """

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # è°ƒç”¨_RepeatSamplerè¿›è¡ŒæŒç»­é‡‡æ ·
        object.__setattr__(self, 'batch_sampler', _RepeatSampler(self.batch_sampler))
        self.iterator = super().__iter__()

    def __len__(self):
        return len(self.batch_sampler.sampler)

    def __iter__(self):
        for i in range(len(self)):
            yield next(self.iterator)


class _RepeatSampler(object):
    """ Sampler that repeats forever
    è¿™éƒ¨åˆ†æ˜¯è¿›è¡ŒæŒç»­é‡‡æ ·
    Args:
        sampler (Sampler)
    """

    def __init__(self, sampler):
        self.sampler = sampler

    def __iter__(self):
        while True:
            yield from iter(self.sampler)


class LoadImages:  # for inference
    def __init__(self, path, img_size=640, stride=32, auto=True):
        p = str(Path(path).resolve())  # os-agnostic absolute path
        if '*' in p:
            files = sorted(glob.glob(p, recursive=True))  # glob
        elif os.path.isdir(p):
            files = sorted(glob.glob(os.path.join(p, '*.*')))  # dir
        elif os.path.isfile(p):
            files = [p]  # files
        else:
            raise Exception(f'ERROR: {p} does not exist')

        images = [x for x in files if x.split('.')[-1].lower() in IMG_FORMATS]
        videos = [x for x in files if x.split('.')[-1].lower() in VID_FORMATS]
        ni, nv = len(images), len(videos)

        self.img_size = img_size
        self.stride = stride
        self.files = images + videos
        self.nf = ni + nv  # number of files
        self.video_flag = [False] * ni + [True] * nv
        self.mode = 'image'
        self.auto = auto
        if any(videos):
            self.new_video(videos[0])  # new video
        else:
            self.cap = None
        assert self.nf > 0, f'No images or videos found in {p}. ' \
                            f'Supported formats are:\nimages: {IMG_FORMATS}\nvideos: {VID_FORMATS}'

    def __iter__(self):
        self.count = 0
        return self

    def __next__(self):
        if self.count == self.nf:
            raise StopIteration
        path = self.files[self.count]

        if self.video_flag[self.count]:
            # Read video
            self.mode = 'video'
            ret_val, img0 = self.cap.read()
            if not ret_val:
                self.count += 1
                self.cap.release()
                if self.count == self.nf:  # last video
                    raise StopIteration
                else:
                    path = self.files[self.count]
                    self.new_video(path)
                    ret_val, img0 = self.cap.read()

            self.frame += 1
            print(f'video {self.count + 1}/{self.nf} ({self.frame}/{self.frames}) {path}: ', end='')

        else:
            # Read image
            self.count += 1
            img0 = cv2.imread(path)  # BGR
            assert img0 is not None, 'Image Not Found ' + path
            print(f'image {self.count}/{self.nf} {path}: ', end='')

        # Padded resize
        img = letterbox(img0, self.img_size, stride=self.stride, auto=self.auto)[0]

        # Convert
        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
        img = np.ascontiguousarray(img)

        return path, img, img0, self.cap

    def new_video(self, path):
        self.frame = 0
        self.cap = cv2.VideoCapture(path)
        self.frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))

    def __len__(self):
        return self.nf  # number of files


class LoadWebcam:  # for inference
    def __init__(self, pipe='0', img_size=640, stride=32):
        self.img_size = img_size
        self.stride = stride
        self.pipe = eval(pipe) if pipe.isnumeric() else pipe
        self.cap = cv2.VideoCapture(self.pipe)  # video capture object
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 3)  # set buffer size

    def __iter__(self):
        self.count = -1
        return self

    def __next__(self):
        self.count += 1
        if cv2.waitKey(1) == ord('q'):  # q to quit
            self.cap.release()
            cv2.destroyAllWindows()
            raise StopIteration

        # Read frame
        ret_val, img0 = self.cap.read()
        img0 = cv2.flip(img0, 1)  # flip left-right

        # Print
        assert ret_val, f'Camera Error {self.pipe}'
        img_path = 'webcam.jpg'
        print(f'webcam {self.count}: ', end='')

        # Padded resize
        img = letterbox(img0, self.img_size, stride=self.stride)[0]

        # Convert
        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
        img = np.ascontiguousarray(img)

        return img_path, img, img0, None

    def __len__(self):
        return 0


class LoadStreams:  # multiple IP or RTSP cameras
    def __init__(self, sources='streams.txt', img_size=640, stride=32, auto=True):
        self.mode = 'stream'
        self.img_size = img_size
        self.stride = stride

        if os.path.isfile(sources):
            with open(sources, 'r') as f:
                sources = [x.strip() for x in f.read().strip().splitlines() if len(x.strip())]
        else:
            sources = [sources]

        n = len(sources)
        self.imgs, self.fps, self.frames, self.threads = [None] * n, [0] * n, [0] * n, [None] * n
        self.sources = [clean_str(x) for x in sources]  # clean source names for later
        self.auto = auto
        for i, s in enumerate(sources):  # index, source
            # Start thread to read frames from video stream
            print(f'{i + 1}/{n}: {s}... ', end='')
            if 'youtube.com/' in s or 'youtu.be/' in s:  # if source is YouTube video
                check_requirements(('pafy', 'youtube_dl'))
                import pafy
                s = pafy.new(s).getbest(preftype="mp4").url  # YouTube URL
            s = eval(s) if s.isnumeric() else s  # i.e. s = '0' local webcam
            cap = cv2.VideoCapture(s)
            assert cap.isOpened(), f'Failed to open {s}'
            w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            self.fps[i] = max(cap.get(cv2.CAP_PROP_FPS) % 100, 0) or 30.0  # 30 FPS fallback
            self.frames[i] = max(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), 0) or float('inf')  # infinite stream fallback

            _, self.imgs[i] = cap.read()  # guarantee first frame
            self.threads[i] = Thread(target=self.update, args=([i, cap]), daemon=True)
            print(f" success ({self.frames[i]} frames {w}x{h} at {self.fps[i]:.2f} FPS)")
            self.threads[i].start()
        print('')  # newline

        # check for common shapes
        s = np.stack([letterbox(x, self.img_size, stride=self.stride, auto=self.auto)[0].shape for x in self.imgs])
        self.rect = np.unique(s, axis=0).shape[0] == 1  # rect inference if all shapes equal
        if not self.rect:
            print('WARNING: Different stream shapes detected. For optimal performance supply similarly-shaped streams.')

    def update(self, i, cap):
        # Read stream `i` frames in daemon thread
        n, f, read = 0, self.frames[i], 1  # frame number, frame array, inference every 'read' frame
        while cap.isOpened() and n < f:
            n += 1
            # _, self.imgs[index] = cap.read()
            cap.grab()
            if n % read == 0:
                success, im = cap.retrieve()
                self.imgs[i] = im if success else self.imgs[i] * 0
            time.sleep(1 / self.fps[i])  # wait time

    def __iter__(self):
        self.count = -1
        return self

    def __next__(self):
        self.count += 1
        if not all(x.is_alive() for x in self.threads) or cv2.waitKey(1) == ord('q'):  # q to quit
            cv2.destroyAllWindows()
            raise StopIteration

        # Letterbox
        img0 = self.imgs.copy()
        img = [letterbox(x, self.img_size, stride=self.stride, auto=self.rect and self.auto)[0] for x in img0]

        # Stack
        img = np.stack(img, 0)

        # Convert
        img = img[..., ::-1].transpose((0, 3, 1, 2))  # BGR to RGB, BHWC to BCHW
        img = np.ascontiguousarray(img)

        return self.sources, img, img0, None

    def __len__(self):
        return len(self.sources)  # 1E12 frames = 32 streams at 30 FPS for 30 years


def img2label_paths(img_paths):
    """
    ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__init__å‡½æ•°ä¸­
    æ ¹æ®imgså›¾ç‰‡çš„è·¯å¾„æ‰¾åˆ°å¯¹åº”labelsçš„è·¯å¾„
    Define label paths as a function of image paths
    :params img_paths: {list: 50}  æ•´ä¸ªæ•°æ®é›†çš„å›¾ç‰‡ç›¸å¯¹è·¯å¾„  ä¾‹å¦‚: '..\\datasets\\VOC\\images\\train2007\\000012.jpg'
                                                        =>   '..\\datasets\\VOC\\labels\\train2007\\000012.jpg'
    """
    # Define label paths as a function of image paths
    # å› ä¸ºpythonæ˜¯è·¨å¹³å°çš„,åœ¨Windowsä¸Š,æ–‡ä»¶çš„è·¯å¾„åˆ†éš”ç¬¦æ˜¯'\',åœ¨Linuxä¸Šæ˜¯'/'
    # ä¸ºäº†è®©ä»£ç åœ¨ä¸åŒçš„å¹³å°ä¸Šéƒ½èƒ½è¿è¡Œï¼Œé‚£ä¹ˆè·¯å¾„åº”è¯¥å†™'\'è¿˜æ˜¯'/'å‘¢ï¼Ÿ os.sepæ ¹æ®ä½ æ‰€å¤„çš„å¹³å°, è‡ªåŠ¨é‡‡ç”¨ç›¸åº”çš„åˆ†éš”ç¬¦å·
    # sa: '\\images\\'    sb: '\\labels\\'
    sa, sb = os.sep + 'images' + os.sep, os.sep + 'labels' + os.sep  # /images/, /labels/ substrings
    # æŠŠimg_pathsä¸­æ‰€æœ‰å›¾ç‰‡è·¯å¾„ä¸­çš„imagesæ›¿æ¢ä¸ºlabels
    return [sb.join(x.rsplit(sa, 1)).rsplit('.', 1)[0] + '.txt' for x in img_paths]


class LoadImagesAndLabels(Dataset):  # for training/testing
    cache_version = 0.5  # dataset labels *.cache version

    def __init__(self, path, img_size=640, batch_size=16, augment=False, hyp=None, rect=False, image_weights=False,
                 cache_images=False, single_cls=False, stride=32, pad=0.0, prefix=''):
        """
        åˆå§‹åŒ–è¿‡ç¨‹å¹¶æ²¡æœ‰ä»€ä¹ˆå®è´¨æ€§çš„æ“ä½œ,æ›´å¤šæ˜¯ä¸€ä¸ªå®šä¹‰å‚æ•°çš„è¿‡ç¨‹ï¼ˆselfå‚æ•°ï¼‰,ä»¥ä¾¿åœ¨__getitem()__ä¸­è¿›è¡Œæ•°æ®å¢å¼ºæ“ä½œ,æ‰€ä»¥è¿™éƒ¨åˆ†ä»£ç åªéœ€è¦æŠ“ä½selfä¸­çš„å„ä¸ªå˜é‡çš„å«ä¹‰å°±ç®—å·®ä¸å¤šäº†
        self.img_files: {list: N} å­˜æ”¾ç€æ•´ä¸ªæ•°æ®é›†å›¾ç‰‡çš„ç›¸å¯¹è·¯å¾„
        self.label_files: {list: N} å­˜æ”¾ç€æ•´ä¸ªæ•°æ®é›†å›¾ç‰‡labelçš„ç›¸å¯¹è·¯å¾„
        cache label -> verify_image_label
        self.labels: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  labelså­˜å‚¨çš„labelå°±éƒ½æ˜¯åŸå§‹label(éƒ½æ˜¯æ­£å¸¸çš„çŸ©å½¢label)
                     å¦åˆ™å°†æ‰€æœ‰å›¾ç‰‡æ­£å¸¸gtçš„labelå­˜å…¥labels ä¸æ­£å¸¸gt(å­˜åœ¨ä¸€ä¸ªå¤šè¾¹å½¢)ç»è¿‡segments2boxesè½¬æ¢ä¸ºæ­£å¸¸çš„çŸ©å½¢label
        self.shapes: æ‰€æœ‰å›¾ç‰‡çš„shape
        self.segments: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  self.segments=None
                       å¦åˆ™å­˜å‚¨æ•°æ®é›†ä¸­æ‰€æœ‰å­˜åœ¨å¤šè¾¹å½¢gtçš„å›¾ç‰‡çš„æ‰€æœ‰åŸå§‹label(è‚¯å®šæœ‰å¤šè¾¹å½¢label ä¹Ÿå¯èƒ½æœ‰çŸ©å½¢æ­£å¸¸label æœªçŸ¥æ•°)
        self.batch: è®°è½½ç€æ¯å¼ å›¾ç‰‡å±äºå“ªä¸ªbatch
        self.n: æ•°æ®é›†ä¸­æ‰€æœ‰å›¾ç‰‡çš„æ•°é‡
        self.indices: è®°è½½ç€æ‰€æœ‰å›¾ç‰‡çš„index
        self.rect=Trueæ—¶self.batch_shapesè®°è½½æ¯ä¸ªbatchçš„shape(åŒä¸€ä¸ªbatchçš„å›¾ç‰‡shapeç›¸åŒ)
        """
        # 1ã€èµ‹å€¼ä¸€äº›åŸºç¡€çš„selfå˜é‡ ç”¨äºåé¢åœ¨__getitem__ä¸­è°ƒç”¨
        self.img_size = img_size    # ç»è¿‡æ•°æ®å¢å¼ºåçš„æ•°æ®å›¾ç‰‡çš„å¤§å°
        self.augment = augment      # æ˜¯å¦å¯åŠ¨æ•°æ®å¢å¼º ä¸€èˆ¬è®­ç»ƒæ—¶æ‰“å¼€ éªŒè¯æ—¶å…³é—­
        self.hyp = hyp              # è¶…å‚åˆ—è¡¨
        # å›¾ç‰‡æŒ‰æƒé‡é‡‡æ ·  Trueå°±å¯ä»¥æ ¹æ®ç±»åˆ«é¢‘ç‡(é¢‘ç‡é«˜çš„æƒé‡å°,åä¹‹å¤§)æ¥è¿›è¡Œé‡‡æ ·  é»˜è®¤False: ä¸ä½œç±»åˆ«åŒºåˆ†
        self.image_weights = image_weights
        self.rect = False if image_weights else rect    # æ˜¯å¦å¯åŠ¨çŸ©å½¢è®­ç»ƒ ä¸€èˆ¬è®­ç»ƒæ—¶å…³é—­ éªŒè¯æ—¶æ‰“å¼€ å¯ä»¥åŠ é€Ÿ
        self.mosaic = self.augment and not self.rect  # load 4 images at a time into a mosaic (only during training)
        # mosaicå¢å¼ºçš„è¾¹ç•Œå€¼  [-320, -320]
        self.mosaic_border = [-img_size // 2, -img_size // 2]
        self.stride = stride        # æœ€å¤§ä¸‹é‡‡æ ·ç‡ 32
        self.path = path            # å›¾ç‰‡è·¯å¾„
        self.albumentations = Albumentations() if augment else None

         # 2ã€å¾—åˆ°pathè·¯å¾„ä¸‹çš„æ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„self.img_files  è¿™é‡Œéœ€è¦è‡ªå·±debugä¸€ä¸‹ ä¸ä¼šå¤ªéš¾
        try:
            f = []  # image files
            for p in path if isinstance(path, list) else [path]:
                # è·å–æ•°æ®é›†è·¯å¾„pathï¼ŒåŒ…å«å›¾ç‰‡è·¯å¾„çš„txtæ–‡ä»¶æˆ–è€…åŒ…å«å›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„
                # ä½¿ç”¨pathlib.Pathç”Ÿæˆä¸æ“ä½œç³»ç»Ÿæ— å…³çš„è·¯å¾„ï¼Œå› ä¸ºä¸åŒæ“ä½œç³»ç»Ÿè·¯å¾„çš„â€˜/â€™ä¼šæœ‰æ‰€ä¸åŒ
                p = Path(p)  # os-agnostic
                # å¦‚æœè·¯å¾„pathä¸ºåŒ…å«å›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„
                if p.is_dir():  # dir
                    # glob.glob: è¿”å›æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨  é€’å½’è·å–pè·¯å¾„ä¸‹æ‰€æœ‰æ–‡ä»¶
                    f += glob.glob(str(p / '**' / '*.*'), recursive=True)
                    # f = list(p.rglob('**/*.*'))  # pathlib
                # å¦‚æœè·¯å¾„pathä¸ºåŒ…å«å›¾ç‰‡è·¯å¾„çš„txtæ–‡ä»¶
                elif p.is_file():  # file
                    with open(p, 'r') as t:
                        t = t.read().strip().splitlines()   # è·å–å›¾ç‰‡è·¯å¾„ï¼Œæ›´æ¢ç›¸å¯¹è·¯å¾„
                        # è·å–æ•°æ®é›†è·¯å¾„çš„ä¸Šçº§çˆ¶ç›®å½•  os.sepä¸ºè·¯å¾„é‡Œçš„åˆ†éš”ç¬¦ï¼ˆä¸åŒè·¯å¾„çš„åˆ†éš”ç¬¦ä¸åŒï¼Œos.sepå¯ä»¥æ ¹æ®ç³»ç»Ÿè‡ªé€‚åº”ï¼‰
                        parent = str(p.parent) + os.sep
                        f += [x.replace('./', parent) if x.startswith('./') else x for x in t]  # local to global path
                        # f += [p.parent / x.lstrip(os.sep) for x in t]  # local to global path (pathlib)
                else:
                    raise Exception(f'{prefix}{p} does not exist')
            # ç ´æŠ˜å·æ›¿æ¢ä¸ºos.sepï¼Œos.path.splitext(x)å°†æ–‡ä»¶åä¸æ‰©å±•ååˆ†å¼€å¹¶è¿”å›ä¸€ä¸ªåˆ—è¡¨
            # ç­›é€‰fä¸­æ‰€æœ‰çš„å›¾ç‰‡æ–‡ä»¶
            self.img_files = sorted([x.replace('/', os.sep) for x in f if x.split('.')[-1].lower() in IMG_FORMATS])
            # self.img_files = sorted([x for x in f if x.suffix[1:].lower() in img_formats])  # pathlib
            assert self.img_files, f'{prefix}No images found'
        except Exception as e:
            raise Exception(f'{prefix}Error loading data from {path}: {e}\nSee {HELP_URL}')

        # Check cache
        # 3ã€æ ¹æ®imgsè·¯å¾„æ‰¾åˆ°labelsçš„è·¯å¾„self.label_files
        self.label_files = img2label_paths(self.img_files)  # labels
        # 4ã€cache label ä¸‹æ¬¡è¿è¡Œè¿™ä¸ªè„šæœ¬çš„æ—¶å€™ç›´æ¥ä»cacheä¸­å–labelè€Œä¸æ˜¯å»æ–‡ä»¶ä¸­å–label é€Ÿåº¦æ›´å¿«
        cache_path = (p if p.is_file() else Path(self.label_files[0]).parent).with_suffix('.cache')
        try:
            # å¦‚æœæœ‰cacheæ–‡ä»¶ï¼Œç›´æ¥åŠ è½½  exists=True: æ˜¯å¦å·²ä»cacheæ–‡ä»¶ä¸­è¯»å‡ºäº†nf, nm, ne, nc, nç­‰ä¿¡æ¯
            cache, exists = np.load(cache_path, allow_pickle=True).item(), True  # load dict
            # å¦‚æœå›¾ç‰‡ç‰ˆæœ¬ä¿¡æ¯æˆ–è€…æ–‡ä»¶åˆ—è¡¨çš„hashå€¼å¯¹ä¸ä¸Šå· è¯´æ˜æœ¬åœ°æ•°æ®é›†å›¾ç‰‡å’Œlabelå¯èƒ½å‘ç”Ÿäº†å˜åŒ– å°±é‡æ–°cache labelæ–‡ä»¶
            assert cache['version'] == 0.4 and cache['hash'] == get_hash(self.label_files + self.img_files)
        except:
            # å¦åˆ™è°ƒç”¨cache_labelsç¼“å­˜æ ‡ç­¾åŠæ ‡ç­¾ç›¸å…³ä¿¡æ¯
            cache, exists = self.cache_labels(cache_path, prefix), False  # cache

        # Display cache
        # æ‰“å°cacheçš„ç»“æœ nf, nm, ne, nc, n = æ‰¾åˆ°çš„æ ‡ç­¾æ•°é‡ï¼Œæ¼æ‰çš„æ ‡ç­¾æ•°é‡ï¼Œç©ºçš„æ ‡ç­¾æ•°é‡ï¼ŒæŸåçš„æ ‡ç­¾æ•°é‡ï¼Œæ€»çš„æ ‡ç­¾æ•°é‡
        nf, nm, ne, nc, n = cache.pop('results')  # found, missing, empty, corrupted, total
        # å¦‚æœå·²ç»ä»cacheæ–‡ä»¶è¯»å‡ºäº†nf nm ne nc nç­‰ä¿¡æ¯ï¼Œç›´æ¥æ˜¾ç¤ºæ ‡ç­¾ä¿¡æ¯  msgsä¿¡æ¯ç­‰
        if exists:
            d = f"Scanning '{cache_path}' images and labels... {nf} found, {nm} missing, {ne} empty, {nc} corrupted"
            tqdm(None, desc=prefix + d, total=n, initial=n)  # display cache results
            if cache['msgs']:
                logging.info('\n'.join(cache['msgs']))  # display warnings
        # æ•°æ®é›†æ²¡æœ‰æ ‡ç­¾ä¿¡æ¯ å°±å‘å‡ºè­¦å‘Šå¹¶æ˜¾ç¤ºæ ‡ç­¾labelä¸‹è½½åœ°å€help_url
        assert nf > 0 or not augment, f'{prefix}No labels in {cache_path}. Can not train without labels. See {HELP_URL}'

        # Read cache
        # 5ã€Read cache  ä»cacheä¸­è¯»å‡ºæœ€æ–°å˜é‡èµ‹ç»™self  æ–¹ä¾¿ç»™forwardä¸­ä½¿ç”¨
        # cacheä¸­çš„é”®å€¼å¯¹æœ€åˆæœ‰: cache[img_file]=[l, shape, segments] cache[hash] cache[results] cache[msg] cache[version]
        # å…ˆä»cacheä¸­å»é™¤cacheæ–‡ä»¶ä¸­å…¶ä»–æ— å…³é”®å€¼å¦‚:'hash', 'version', 'msgs'ç­‰éƒ½åˆ é™¤
        [cache.pop(k) for k in ('hash', 'version', 'msgs')]  # remove items
        # popæ‰resultsã€hashã€versionã€msgsååªå‰©ä¸‹cache[img_file]=[l, shape, segments]
        # cache.values(): å–cacheä¸­æ‰€æœ‰å€¼ å¯¹åº”æ‰€æœ‰l, shape, segments
        # labels: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  labelså­˜å‚¨çš„labelå°±éƒ½æ˜¯åŸå§‹label(éƒ½æ˜¯æ­£å¸¸çš„çŸ©å½¢label)
        #         å¦åˆ™å°†æ‰€æœ‰å›¾ç‰‡æ­£å¸¸gtçš„labelå­˜å…¥labels ä¸æ­£å¸¸gt(å­˜åœ¨ä¸€ä¸ªå¤šè¾¹å½¢)ç»è¿‡segments2boxesè½¬æ¢ä¸ºæ­£å¸¸çš„çŸ©å½¢label
        # shapes: æ‰€æœ‰å›¾ç‰‡çš„shape
        # self.segments: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  self.segments=None
        #                å¦åˆ™å­˜å‚¨æ•°æ®é›†ä¸­æ‰€æœ‰å­˜åœ¨å¤šè¾¹å½¢gtçš„å›¾ç‰‡çš„æ‰€æœ‰åŸå§‹label(è‚¯å®šæœ‰å¤šè¾¹å½¢label ä¹Ÿå¯èƒ½æœ‰çŸ©å½¢æ­£å¸¸label æœªçŸ¥æ•°)
        # zip æ˜¯å› ä¸ºcacheä¸­æ‰€æœ‰labelsã€shapesã€segmentsä¿¡æ¯éƒ½æ˜¯æŒ‰æ¯å¼ imgåˆ†å¼€å­˜å‚¨çš„, zipæ˜¯å°†æ‰€æœ‰å›¾ç‰‡å¯¹åº”çš„ä¿¡æ¯å åœ¨ä¸€èµ·
        labels, shapes, self.segments = zip(*cache.values()) # segments: éƒ½æ˜¯[]
        self.labels = list(labels)  # labels to list
        self.shapes = np.array(shapes, dtype=np.float64)    # image shapes to float64
        self.img_files = list(cache.keys())  # update æ›´æ–°æ‰€æœ‰å›¾ç‰‡çš„img_filesä¿¡æ¯
        self.label_files = img2label_paths(cache.keys())  # update æ›´æ–°æ‰€æœ‰å›¾ç‰‡çš„label_filesä¿¡æ¯
        if single_cls:
            for x in self.labels:
                x[:, 0] = 0

        n = len(shapes)  # number of images
        bi = np.floor(np.arange(n) / batch_size).astype(np.int)  # batch index
        nb = bi[-1] + 1  # number of batches
        self.batch = bi  # batch index of image
        self.n = n
        self.indices = range(n) # æ‰€æœ‰å›¾ç‰‡çš„index

        # #**********************************************************#
        # #Update labels
        # include_class = [0,1,2,3,5,6,7]  # filter labels to include only these classes (optional)
        # include_class_array = np.array(include_class).reshape(1, -1)
        # for i, (label, segment) in enumerate(zip(self.labels, self.segments)):
        #     if include_class:
        #         j = (label[:, 0:1] == include_class_array).any(1)
        #         self.labels[i] = label[j]
        #         if segment:
        #             self.segments[i] = segment[j]
        #     if single_cls:  # single-class training, merge all classes into 0
        #         self.labels[i][:, 0] = 0
        #         if segment:
        #             self.segments[i][:, 0] = 0
        # #**********************************************************#

        
        # Rectangular Training
        # 6ã€ä¸ºRectangular Trainingä½œå‡†å¤‡
        # è¿™é‡Œä¸»è¦æ˜¯æ³¨æ„shapesçš„ç”Ÿæˆ è¿™ä¸€æ­¥å¾ˆé‡è¦ å› ä¸ºå¦‚æœé‡‡æ ·çŸ©å½¢è®­ç»ƒé‚£ä¹ˆæ•´ä¸ªbatchçš„å½¢çŠ¶è¦ä¸€æ · å°±è¦è®¡ç®—è¿™ä¸ªç¬¦åˆæ•´ä¸ªbatchçš„shape
        # è€Œä¸”è¿˜è¦å¯¹æ•°æ®é›†æŒ‰ç…§é«˜å®½æ¯”è¿›è¡Œæ’åº è¿™æ ·æ‰èƒ½ä¿è¯åŒä¸€ä¸ªbatchçš„å›¾ç‰‡çš„å½¢çŠ¶å·®ä¸å¤šç›¸åŒ å†é€‰åˆ™ä¸€ä¸ªå…±åŒçš„shapeä»£ä»·ä¹Ÿæ¯”è¾ƒå°
        if self.rect:
            # Sort by aspect ratio
            s = self.shapes  # wh
            ar = s[:, 1] / s[:, 0]  # aspect ratio
            irect = ar.argsort()    # æ ¹æ®é«˜å®½æ¯”æ’åº
            self.img_files = [self.img_files[i] for i in irect]         # è·å–æ’åºåçš„img_files
            self.label_files = [self.label_files[i] for i in irect]     # è·å–æ’åºåçš„label_files
            self.labels = [self.labels[i] for i in irect]               # è·å–æ’åºåçš„labels
            self.shapes = s[irect]  # wh                                # è·å–æ’åºåçš„wh
            ar = ar[irect]                                              # è·å–æ’åºåçš„aspect ratio

            # Set training image shapes     è®¡ç®—æ¯ä¸ªbatché‡‡ç”¨çš„ç»Ÿä¸€å°ºåº¦
            shapes = [[1, 1]] * nb          # nb: number of batches
            for i in range(nb):
                ari = ar[bi == i]           # bi: batch index
                mini, maxi = ari.min(), ari.max()   # è·å–ç¬¬iä¸ªbatchä¸­ï¼Œæœ€å°å’Œæœ€å¤§é«˜å®½æ¯”
                # å¦‚æœé«˜/å®½å°äº1(w > h)ï¼Œå°†wè®¾ä¸ºimg_sizeï¼ˆä¿è¯åŸå›¾åƒå°ºåº¦ä¸å˜è¿›è¡Œç¼©æ”¾ï¼‰
                if maxi < 1:
                    shapes[i] = [maxi, 1]   # maxi: hç›¸å¯¹æŒ‡å®šå°ºåº¦çš„æ¯”ä¾‹  1: wç›¸å¯¹æŒ‡å®šå°ºåº¦çš„æ¯”ä¾‹
                # å¦‚æœé«˜/å®½å¤§äº1(w < h)ï¼Œå°†hè®¾ç½®ä¸ºimg_sizeï¼ˆä¿è¯åŸå›¾åƒå°ºåº¦ä¸å˜è¿›è¡Œç¼©æ”¾ï¼‰
                elif mini > 1:
                    shapes[i] = [1, 1 / mini]

            # è®¡ç®—æ¯ä¸ªbatchè¾“å…¥ç½‘ç»œçš„shapeå€¼(å‘ä¸Šè®¾ç½®ä¸º32çš„æ•´æ•°å€)
            # è¦æ±‚æ¯ä¸ªbatch_shapesçš„é«˜å®½éƒ½æ˜¯32çš„æ•´æ•°å€ï¼Œæ‰€ä»¥è¦å…ˆé™¤ä»¥32ï¼Œå–æ•´å†ä¹˜ä»¥32ï¼ˆä¸è¿‡img_sizeå¦‚æœæ˜¯32å€æ•°è¿™é‡Œå°±æ²¡å¿…è¦äº†ï¼‰
            self.batch_shapes = np.ceil(np.array(shapes) * img_size / stride + pad).astype(np.int) * stride

        # Cache images into memory for faster training (WARNING: large datasets may exceed system RAM)  
        # 7ã€æ˜¯å¦éœ€è¦cache image ä¸€èˆ¬æ˜¯False å› ä¸ºRAMä¼šä¸è¶³  cache labelè¿˜å¯ä»¥ ä½†æ˜¯cache imageå°±å¤ªå¤§äº† æ‰€ä»¥ä¸€èˆ¬ä¸ç”¨      
        self.imgs, self.img_npy = [None] * n, [None] * n
        if cache_images:
            if cache_images == 'disk':
                self.im_cache_dir = Path(Path(self.img_files[0]).parent.as_posix() + '_npy')
                self.img_npy = [self.im_cache_dir / Path(f).with_suffix('.npy').name for f in self.img_files]
                self.im_cache_dir.mkdir(parents=True, exist_ok=True)
            gb = 0  # Gigabytes of cached images
            self.img_hw0, self.img_hw = [None] * n, [None] * n
            results = ThreadPool(NUM_THREADS).imap(lambda x: load_image(*x), zip(repeat(self), range(n)))
            pbar = tqdm(enumerate(results), total=n)
            for i, x in pbar:
                if cache_images == 'disk':
                    if not self.img_npy[i].exists():
                        np.save(self.img_npy[i].as_posix(), x[0])
                    gb += self.img_npy[i].stat().st_size
                else:
                    self.imgs[i], self.img_hw0[i], self.img_hw[i] = x  # im, hw_orig, hw_resized = load_image(self, i)
                    gb += self.imgs[i].nbytes
                pbar.desc = f'{prefix}Caching images ({gb / 1E9:.1f}GB {cache_images})'
            pbar.close()

    def cache_labels(self, path=Path('./labels.cache'), prefix=''):
        # Cache dataset labels, check images and read shapes
        """
        ç”¨åœ¨__init__å‡½æ•°ä¸­  cacheæ•°æ®é›†label
        åŠ è½½labelä¿¡æ¯ç”Ÿæˆcacheæ–‡ä»¶   Cache dataset labels, check images and read shapes
        :params path: cacheæ–‡ä»¶ä¿å­˜åœ°å€
        :params prefix: æ—¥å¿—å¤´éƒ¨ä¿¡æ¯(å½©æ‰“é«˜äº®éƒ¨åˆ†)
        :return x: cacheä¸­ä¿å­˜çš„å­—å…¸
               åŒ…æ‹¬çš„ä¿¡æ¯æœ‰: x[im_file] = [l, shape, segments]
                          ä¸€å¼ å›¾ç‰‡ä¸€ä¸ªlabelç›¸å¯¹åº”çš„ä¿å­˜åˆ°x, æœ€ç»ˆxä¼šä¿å­˜æ‰€æœ‰å›¾ç‰‡çš„ç›¸å¯¹è·¯å¾„ã€gtæ¡†çš„ä¿¡æ¯ã€å½¢çŠ¶shapeã€æ‰€æœ‰çš„å¤šè¾¹å½¢gtä¿¡æ¯
                              im_file: å½“å‰è¿™å¼ å›¾ç‰‡çš„pathç›¸å¯¹è·¯å¾„
                              l: å½“å‰è¿™å¼ å›¾ç‰‡çš„æ‰€æœ‰gtæ¡†çš„labelä¿¡æ¯(ä¸åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, cls+xywh(normalized)]
                              shape: å½“å‰è¿™å¼ å›¾ç‰‡çš„å½¢çŠ¶ shape
                              segments: å½“å‰è¿™å¼ å›¾ç‰‡æ‰€æœ‰gtçš„labelä¿¡æ¯(åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, xy1...]
                           hash: å½“å‰å›¾ç‰‡å’Œlabelæ–‡ä»¶çš„hashå€¼  1
                           results: æ‰¾åˆ°çš„labelä¸ªæ•°nf, ä¸¢å¤±labelä¸ªæ•°nm, ç©ºlabelä¸ªæ•°ne, ç ´æŸlabelä¸ªæ•°nc, æ€»img/labelä¸ªæ•°len(self.img_files)
                           msgs: æ‰€æœ‰æ•°æ®é›†çš„msgsä¿¡æ¯
                           version: å½“å‰cache version
        """
        x = {}  # dict  åˆå§‹åŒ–æœ€ç»ˆcacheä¸­ä¿å­˜çš„å­—å…¸dict
        # åˆå§‹åŒ–number missing, found, empty, corrupt, messages
        # åˆå§‹åŒ–æ•´ä¸ªæ•°æ®é›†: æ¼æ‰çš„æ ‡ç­¾(label)æ€»æ•°é‡, æ‰¾åˆ°çš„æ ‡ç­¾(label)æ€»æ•°é‡, ç©ºçš„æ ‡ç­¾(label)æ€»æ•°é‡, é”™è¯¯æ ‡ç­¾(label)æ€»æ•°é‡, æ‰€æœ‰é”™è¯¯ä¿¡æ¯
        nm, nf, ne, nc, msgs = 0, 0, 0, 0, []  # number missing, found, empty, corrupt, messages
        desc = f"{prefix}Scanning '{path.parent / path.stem}' images and labels..."
        # å¤šè¿›ç¨‹è°ƒç”¨verify_image_labelå‡½æ•°
        with Pool(NUM_THREADS) as pool:
            # å®šä¹‰pbarè¿›åº¦æ¡
            # pool.imap_unordered: å¯¹å¤§é‡æ•°æ®éå†å¤šè¿›ç¨‹è®¡ç®— è¿”å›ä¸€ä¸ªè¿­ä»£å™¨
            # æŠŠself.img_files, self.label_files, repeat(prefix) listä¸­çš„å€¼ä½œä¸ºå‚æ•°ä¾æ¬¡é€å…¥(ä¸€æ¬¡é€ä¸€ä¸ª)verify_image_labelå‡½æ•°
            pbar = tqdm(pool.imap_unordered(verify_image_label, zip(self.img_files, self.label_files, repeat(prefix))),
                        desc=desc, total=len(self.img_files))
            # im_file: å½“å‰è¿™å¼ å›¾ç‰‡çš„pathç›¸å¯¹è·¯å¾„
            # l: [gt_num, cls+xywh(normalized)]
            #    å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ lå°±å­˜å‚¨åŸlabel(å…¨éƒ¨æ˜¯æ­£å¸¸çŸ©å½¢æ ‡ç­¾)
            #    å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾  lå°±å­˜å‚¨ç»è¿‡segments2boxeså¤„ç†å¥½çš„æ ‡ç­¾(æ­£å¸¸çŸ©å½¢æ ‡ç­¾ä¸å¤„ç† å¤šè¾¹å½¢æ ‡ç­¾è½¬åŒ–ä¸ºçŸ©å½¢æ ‡ç­¾)
            # shape: å½“å‰è¿™å¼ å›¾ç‰‡çš„å½¢çŠ¶ shape
            # segments: å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å­˜å‚¨None
            #           å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å°±æŠŠè¿™å¼ å›¾ç‰‡çš„æ‰€æœ‰labelå­˜å‚¨åˆ°segmentsä¸­(è‹¥å¹²ä¸ªæ­£å¸¸gt è‹¥å¹²ä¸ªå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, xy1...]
            # nm_f(nm): number missing å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦ä¸¢å¤±         ä¸¢å¤±=1    å­˜åœ¨=0
            # nf_f(nf): number found å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦å­˜åœ¨           å­˜åœ¨=1    ä¸¢å¤±=0
            # ne_f(ne): number empty å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦æ˜¯ç©ºçš„         ç©ºçš„=1    æ²¡ç©º=0
            # nc_f(nc): number corrupt å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ–‡ä»¶æ˜¯å¦æ˜¯ç ´æŸçš„  ç ´æŸçš„=1  æ²¡ç ´æŸ=0
            # msg: è¿”å›çš„msgä¿¡æ¯  labelæ–‡ä»¶å®Œå¥½=â€˜â€™  labelæ–‡ä»¶ç ´æŸ=warningä¿¡æ¯
            for im_file, l, shape, segments, nm_f, nf_f, ne_f, nc_f, msg in pbar:
                nm += nm_f  # ç´¯åŠ æ€»number missing label
                nf += nf_f  # ç´¯åŠ æ€»number found label
                ne += ne_f  # ç´¯åŠ æ€»number empty label
                nc += nc_f  # ç´¯åŠ æ€»number corrupt label
                if im_file:
                    x[im_file] = [l, shape, segments]   # ä¿¡æ¯å­˜å…¥å­—å…¸ key=im_file  value=[l, shape, segments]
                if msg:
                    msgs.append(msg)    # å°†msgåŠ å…¥æ€»msg
                pbar.desc = f"{desc}{nf} found, {nm} missing, {ne} empty, {nc} corrupted"   # æ—¥å¿—

        pbar.close()    # å…³é—­è¿›åº¦æ¡
        # æ—¥å¿—æ‰“å°æ‰€æœ‰msgä¿¡æ¯
        if msgs:
            logging.info('\n'.join(msgs))
        # ä¸€å¼ labeléƒ½æ²¡æ‰¾åˆ° æ—¥å¿—æ‰“å°help_urlä¸‹è½½åœ°å€
        if nf == 0:
            logging.info(f'{prefix}WARNING: No labels found in {path}. See {HELP_URL}')
        x['hash'] = get_hash(self.label_files + self.img_files) # å°†å½“å‰å›¾ç‰‡å’Œlabelæ–‡ä»¶çš„hashå€¼å­˜å…¥æœ€ç»ˆå­—å…¸dist
        x['results'] = nf, nm, ne, nc, len(self.img_files)      # å°†nf, nm, ne, nc, len(self.img_files)å­˜å…¥æœ€ç»ˆå­—å…¸dist
        x['msgs'] = msgs  # warnings    å°†æ‰€æœ‰æ•°æ®é›†çš„msgsä¿¡æ¯å­˜å…¥æœ€ç»ˆå­—å…¸dist
        x['version'] = 0.4  # cache version     å°†å½“å‰cache versionå­˜å…¥æœ€ç»ˆå­—å…¸dist
        try:
            np.save(path, x)  # save cache for next time
            path.with_suffix('.cache.npy').rename(path)  # remove .npy suffix
            logging.info(f'{prefix}New cache created: {path}')
        except Exception as e:
            logging.info(f'{prefix}WARNING: Cache directory {path.parent} is not writeable: {e}')  # path not writeable
        return x

    def __len__(self):
        return len(self.img_files)

    # def __iter__(self):
    #     self.count = -1
    #     print('ran dataset iter')
    #     #self.shuffled_vector = np.random.permutation(self.nF) if self.augment else np.arange(self.nF)
    #     return self

    def __getitem__(self, index):
        """
        è¿™éƒ¨åˆ†æ˜¯æ•°æ®å¢å¼ºå‡½æ•°ï¼Œä¸€èˆ¬ä¸€æ¬¡æ€§æ‰§è¡Œbatch_sizeæ¬¡ã€‚
        è®­ç»ƒ æ•°æ®å¢å¼º: mosaic(random_perspective) + hsv + ä¸Šä¸‹å·¦å³ç¿»è½¬
        æµ‹è¯• æ•°æ®å¢å¼º: letterbox
        :return torch.from_numpy(img): è¿™ä¸ªindexçš„å›¾ç‰‡æ•°æ®(å¢å¼ºå) [3, 640, 640]
        :return labels_out: è¿™ä¸ªindexå›¾ç‰‡çš„gt label [6, 6] = [gt_num, 0+class+xywh(normalized)]
        :return self.img_files[index]: è¿™ä¸ªindexå›¾ç‰‡çš„è·¯å¾„åœ°å€
        :return shapes: è¿™ä¸ªbatchçš„å›¾ç‰‡çš„shapes æµ‹è¯•æ—¶(çŸ©å½¢è®­ç»ƒ)æ‰æœ‰  éªŒè¯æ—¶ä¸ºNone   for COCO mAP rescaling
        """
        # è¿™é‡Œå¯ä»¥é€šè¿‡ä¸‰ç§å½¢å¼è·å–è¦è¿›è¡Œæ•°æ®å¢å¼ºçš„å›¾ç‰‡index  linear, shuffled, or image_weights
        index = self.indices[index]  # linear, shuffled, or image_weights

        hyp = self.hyp  # è¶…å‚ åŒ…å«ä¼—å¤šæ•°æ®å¢å¼ºè¶…å‚
        mosaic = self.mosaic and random.random() < hyp['mosaic']
        # mosaicå¢å¼º å¯¹å›¾åƒè¿›è¡Œ4å¼ å›¾æ‹¼æ¥è®­ç»ƒ  ä¸€èˆ¬è®­ç»ƒæ—¶è¿è¡Œ
        # mosaic + MixUp
        if mosaic:
            # Load mosaic
            img, labels = load_mosaic(self, index)
            shapes = None

            # MixUp augmentation
            # mixupæ•°æ®å¢å¼º
            if random.random() < hyp['mixup']:  # hyp['mixup']=0 é»˜è®¤ä¸º0åˆ™å…³é—­ é»˜è®¤ä¸º1åˆ™100%æ‰“å¼€
                # *load_mosaic(self, random.randint(0, self.n - 1)) éšæœºä»æ•°æ®é›†ä¸­ä»»é€‰ä¸€å¼ å›¾ç‰‡å’Œæœ¬å¼ å›¾ç‰‡è¿›è¡Œmixupæ•°æ®å¢å¼º
                # img:   ä¸¤å¼ å›¾ç‰‡èåˆä¹‹åçš„å›¾ç‰‡ numpy (640, 640, 3)
                # labels: ä¸¤å¼ å›¾ç‰‡èåˆä¹‹åçš„æ ‡ç­¾label [M+N, cls+x1y1x2y2]
                img, labels = mixup(img, labels, *load_mosaic(self, random.randint(0, self.n - 1)))

                # æµ‹è¯•ä»£ç  æµ‹è¯•MixUpæ•ˆæœ
                # cv2.imshow("MixUp", img)
                # cv2.waitKey(0)
                # cv2.destroyAllWindows()
                # print(img.shape)   # (640, 640, 3)

        # å¦åˆ™: è½½å…¥å›¾ç‰‡ + Letterbox  (val)
        else:
            # Load image
            # è½½å…¥å›¾ç‰‡  è½½å…¥å›¾ç‰‡åè¿˜ä¼šè¿›è¡Œä¸€æ¬¡resize  å°†å½“å‰å›¾ç‰‡çš„æœ€é•¿è¾¹ç¼©æ”¾åˆ°æŒ‡å®šçš„å¤§å°(512), è¾ƒå°è¾¹åŒæ¯”ä¾‹ç¼©æ”¾
            # load image img=(343, 512, 3)=(h, w, c)  (h0, w0)=(335, 500)  numpy  index=4
            # img: resizeåçš„å›¾ç‰‡   (h0, w0): åŸå§‹å›¾ç‰‡çš„hw  (h, w): resizeåçš„å›¾ç‰‡çš„hw
            # è¿™ä¸€æ­¥æ˜¯å°†(335, 500, 3) resize-> (343, 512, 3)
            img, (h0, w0), (h, w) = load_image(self, index)

            # æµ‹è¯•ä»£ç  æµ‹è¯•load_imageæ•ˆæœ
            # cv2.imshow("load_image", img)
            # cv2.waitKey(0)
            # cv2.destroyAllWindows()
            # print(img.shape)   # (640, 640, 3)

            # Letterbox
            # letterboxä¹‹å‰ç¡®å®šè¿™å¼ å½“å‰å›¾ç‰‡letterboxä¹‹åçš„shape  å¦‚æœä¸ç”¨self.rectçŸ©å½¢è®­ç»ƒshapeå°±æ˜¯self.img_size
            # å¦‚æœä½¿ç”¨self.rectçŸ©å½¢è®­ç»ƒshapeå°±æ˜¯å½“å‰batchçš„shape å› ä¸ºçŸ©å½¢è®­ç»ƒçš„è¯æˆ‘ä»¬æ•´ä¸ªbatchçš„shapeå¿…é¡»ç»Ÿä¸€
            shape = self.batch_shapes[self.batch[index]] if self.rect else self.img_size  # final letterboxed shape
            # letterbox è¿™ä¸€æ­¥å°†ç¬¬ä¸€æ­¥ç¼©æ”¾å¾—åˆ°çš„å›¾ç‰‡å†ç¼©æ”¾åˆ°å½“å‰batchæ‰€éœ€è¦çš„å°ºåº¦ (343, 512, 3) pad-> (384, 512, 3)
            # (çŸ©å½¢æ¨ç†éœ€è¦ä¸€ä¸ªbatchçš„æ‰€æœ‰å›¾ç‰‡çš„shapeå¿…é¡»ç›¸åŒï¼Œè€Œè¿™ä¸ªshapeåœ¨initå‡½æ•°ä¸­ä¿æŒåœ¨self.batch_shapesä¸­)
            # è¿™é‡Œæ²¡æœ‰ç¼©æ”¾æ“ä½œï¼Œæ‰€ä»¥è¿™é‡Œçš„ratioæ°¸è¿œéƒ½æ˜¯(1.0, 1.0)  pad=(0.0, 20.5)
            img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)
            shapes = (h0, w0), ((h / h0, w / w0), pad)  # for COCO mAP rescaling

            # å›¾ç‰‡letterboxä¹‹ålabelçš„åæ ‡ä¹Ÿè¦ç›¸åº”å˜åŒ–  æ ¹æ®padè°ƒæ•´labelåæ ‡ å¹¶å°†å½’ä¸€åŒ–çš„xywh -> æœªå½’ä¸€åŒ–çš„xyxy
            labels = self.labels[index].copy()
            if labels.size:  # normalized xywh to pixel xyxy format
                labels[:, 1:] = xywhn2xyxy(labels[:, 1:], ratio[0] * w, ratio[1] * h, padw=pad[0], padh=pad[1])

            # æµ‹è¯•ä»£ç  æµ‹è¯•letterboxæ•ˆæœ
            # cv2.imshow("letterbox", img)
            # cv2.waitKey(0)
            # cv2.destroyAllWindows()
            # print(img.shape)   # (640, 640, 3)


            if self.augment:
                # random_perspectiveå¢å¼º: éšæœºå¯¹å›¾ç‰‡è¿›è¡Œæ—‹è½¬ï¼Œå¹³ç§»ï¼Œç¼©æ”¾ï¼Œè£å‰ªï¼Œé€è§†å˜æ¢
                img, labels = random_perspective(img, labels,
                                                 degrees=hyp['degrees'],
                                                 translate=hyp['translate'],
                                                 scale=hyp['scale'],
                                                 shear=hyp['shear'],
                                                 perspective=hyp['perspective'])

        nl = len(labels)  # number of labels
        if nl:
            # xyxy to xywh normalized
            labels[:, 1:5] = xyxy2xywhn(labels[:, 1:5], w=img.shape[1], h=img.shape[0], clip=True, eps=1E-3)

        if self.augment:
            # Albumentations
            img, labels = self.albumentations(img, labels)
            nl = len(labels)  # update after albumentations

            # HSV color-space è‰²åŸŸç©ºé—´å¢å¼º
            augment_hsv(img, hgain=hyp['hsv_h'], sgain=hyp['hsv_s'], vgain=hyp['hsv_v'])

            # Flip up-down
            # éšæœºä¸Šä¸‹ç¿»è½¬ flip up-down
            if random.random() < hyp['flipud']:
                img = np.flipud(img)    # np.flipud å°†æ•°ç»„åœ¨ä¸Šä¸‹æ–¹å‘ç¿»è½¬ã€‚
                if nl:
                    labels[:, 2] = 1 - labels[:, 2]     # 1 - y_center  labelä¹Ÿè¦æ˜ å°„

            # Flip left-right
            # éšæœºå·¦å³ç¿»è½¬ flip left-right
            if random.random() < hyp['fliplr']:
                img = np.fliplr(img)    # np.fliplr å°†æ•°ç»„åœ¨å·¦å³æ–¹å‘ç¿»è½¬
                if nl:
                    labels[:, 1] = 1 - labels[:, 1]     # 1 - x_center  labelä¹Ÿè¦æ˜ å°„

            # Cutouts
            # labels = cutout(img, labels, p=0.5)

        # 6ä¸ªå€¼çš„tensor åˆå§‹åŒ–æ ‡ç­¾æ¡†å¯¹åº”çš„å›¾ç‰‡åºå·, é…åˆä¸‹é¢çš„collate_fnä½¿ç”¨
        labels_out = torch.zeros((nl, 6))
        if nl:
            labels_out[:, 1:] = torch.from_numpy(labels)    # numpy to tensor

        # Convert BGR->RGB  HWC->CHW
        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
        img = np.ascontiguousarray(img) # imgå˜æˆå†…å­˜è¿ç»­çš„æ•°æ®  åŠ å¿«è¿ç®—

        return torch.from_numpy(img), labels_out, self.img_files[index], shapes

    @staticmethod
    def collate_fn(batch):
        """
        è¿™ä¸ªå‡½æ•°ä¼šåœ¨create_dataloaderä¸­ç”Ÿæˆdataloaderæ—¶è°ƒç”¨ï¼š
        æ•´ç†å‡½æ•°  å°†imageå’Œlabelæ•´åˆåˆ°ä¸€èµ·
        :return torch.stack(img, 0): å¦‚[16, 3, 640, 640] æ•´ä¸ªbatchçš„å›¾ç‰‡
        :return torch.cat(label, 0): å¦‚[15, 6] [num_target, img_index+class_index+xywh(normalized)] æ•´ä¸ªbatchçš„label
        :return path: æ•´ä¸ªbatchæ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„
        :return shapes: (h0, w0), ((h / h0, w / w0), pad)    for COCO mAP rescaling
        pytorchçš„DataLoaderæ‰“åŒ…ä¸€ä¸ªbatchçš„æ•°æ®é›†æ—¶è¦ç»è¿‡æ­¤å‡½æ•°è¿›è¡Œæ‰“åŒ… é€šè¿‡é‡å†™æ­¤å‡½æ•°å®ç°æ ‡ç­¾ä¸å›¾ç‰‡å¯¹åº”çš„åˆ’åˆ†ï¼Œä¸€ä¸ªbatchä¸­å“ªäº›æ ‡ç­¾å±äºå“ªä¸€å¼ å›¾ç‰‡,å½¢å¦‚
            [[0, 6, 0.5, 0.5, 0.26, 0.35],
             [0, 6, 0.5, 0.5, 0.26, 0.35],
             [1, 6, 0.5, 0.5, 0.26, 0.35],
             [2, 6, 0.5, 0.5, 0.26, 0.35],]
           å‰ä¸¤è¡Œæ ‡ç­¾å±äºç¬¬ä¸€å¼ å›¾ç‰‡, ç¬¬ä¸‰è¡Œå±äºç¬¬äºŒå¼ ã€‚ã€‚ã€‚
        """
        # img: ä¸€ä¸ªtuple ç”±batch_sizeä¸ªtensorç»„æˆ æ•´ä¸ªbatchä¸­æ¯ä¸ªtensorè¡¨ç¤ºä¸€å¼ å›¾ç‰‡
        # label: ä¸€ä¸ªtuple ç”±batch_sizeä¸ªtensorç»„æˆ æ¯ä¸ªtensorå­˜æ”¾ä¸€å¼ å›¾ç‰‡çš„æ‰€æœ‰çš„targetä¿¡æ¯
        #        label[6, object_num] 6ä¸­çš„ç¬¬ä¸€ä¸ªæ•°ä»£è¡¨ä¸€ä¸ªbatchä¸­çš„ç¬¬å‡ å¼ å›¾
        # path: ä¸€ä¸ªtuple ç”±4ä¸ªstrç»„æˆ, æ¯ä¸ªstrå¯¹åº”ä¸€å¼ å›¾ç‰‡çš„åœ°å€ä¿¡æ¯
        img, label, path, shapes = zip(*batch)  # transposed
        for i, l in enumerate(label):
            l[:, 0] = i  # add target image index for build_targets()
        # è¿”å›çš„img=[batch_size, 3, 736, 736]
        #      torch.stack(img, 0): å°†batch_sizeä¸ª[3, 736, 736]çš„çŸ©é˜µæ‹¼æˆä¸€ä¸ª[batch_size, 3, 736, 736]
        # label=[target_sums, 6]  6ï¼šè¡¨ç¤ºå½“å‰targetå±äºå“ªä¸€å¼ å›¾+class+x+y+w+h
        #      torch.cat(label, 0): å°†[n1,6]ã€[n2,6]ã€[n3,6]...æ‹¼æ¥æˆ[n1+n2+n3+..., 6]
        # è¿™é‡Œä¹‹æ‰€ä»¥æ‹¼æ¥çš„æ–¹å¼ä¸åŒæ˜¯å› ä¸ºimgæ‹¼æ¥çš„æ—¶å€™å®ƒçš„æ¯ä¸ªéƒ¨åˆ†çš„å½¢çŠ¶æ˜¯ç›¸åŒçš„ï¼Œéƒ½æ˜¯[3, 736, 736]
        # è€Œæˆ‘labelçš„æ¯ä¸ªéƒ¨åˆ†çš„å½¢çŠ¶æ˜¯ä¸ä¸€å®šç›¸åŒçš„ï¼Œæ¯å¼ å›¾çš„ç›®æ ‡ä¸ªæ•°æ˜¯ä¸ä¸€å®šç›¸åŒçš„ï¼ˆlabelè‚¯å®šä¹Ÿå¸Œæœ›ç”¨stack,æ›´æ–¹ä¾¿,ä½†æ˜¯ä¸èƒ½é‚£æ ·æ‹¼ï¼‰
        # å¦‚æœæ¯å¼ å›¾çš„ç›®æ ‡ä¸ªæ•°æ˜¯ç›¸åŒçš„ï¼Œé‚£æˆ‘ä»¬å°±å¯èƒ½ä¸éœ€è¦é‡å†™collate_fnå‡½æ•°äº†
        return torch.stack(img, 0), torch.cat(label, 0), path, shapes

    @staticmethod
    def collate_fn4(batch):
        """
        åŒæ ·åœ¨create_dataloaderä¸­ç”Ÿæˆdataloaderæ—¶è°ƒç”¨ï¼š
        è¿™é‡Œæ˜¯yolo-v5ä½œè€…å®éªŒæ€§çš„ä¸€ä¸ªä»£ç  quad-collate function å½“train.pyçš„optå‚æ•°quad=True åˆ™è°ƒç”¨collate_fn4ä»£æ›¿collate_fn
        ä½œç”¨:  å¦‚ä¹‹å‰ç”¨collate_fnå¯ä»¥è¿”å›å›¾ç‰‡[16, 3, 640, 640] ç»è¿‡collate_fn4åˆ™è¿”å›å›¾ç‰‡[4, 3, 1280, 1280]
              å°†4å¼ mosaicå›¾ç‰‡[1, 3, 640, 640]åˆæˆä¸€å¼ å¤§çš„mosaicå›¾ç‰‡[1, 3, 1280, 1280]
              å°†ä¸€ä¸ªbatchçš„å›¾ç‰‡æ¯å››å¼ å¤„ç†, 0.5çš„æ¦‚ç‡å°†å››å¼ å›¾ç‰‡æ‹¼æ¥åˆ°ä¸€å¼ å¤§å›¾ä¸Šè®­ç»ƒ, 0.5æ¦‚ç‡ç›´æ¥å°†æŸå¼ å›¾ç‰‡ä¸Šé‡‡æ ·ä¸¤å€è®­ç»ƒ
        """
        # img: æ•´ä¸ªbatchçš„å›¾ç‰‡ [16, 3, 640, 640]
        # label: æ•´ä¸ªbatchçš„labelæ ‡ç­¾ [num_target, img_index+class_index+xywh(normalized)]
        # path: æ•´ä¸ªbatchæ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„
        # shapes: (h0, w0), ((h / h0, w / w0), pad)    for COCO mAP rescaling
        img, label, path, shapes = zip(*batch)  # transposed
        n = len(shapes) // 4    # collate_fn4å¤„ç†åè¿™ä¸ªbatchä¸­å›¾ç‰‡çš„ä¸ªæ•°
        img4, label4, path4, shapes4 = [], [], path[:n], shapes[:n] # åˆå§‹åŒ–

        ho = torch.tensor([[0., 0, 0, 1, 0, 0]])
        wo = torch.tensor([[0., 0, 1, 0, 0, 0]])
        s = torch.tensor([[1, 1, .5, .5, .5, .5]])  # scale
        for i in range(n):  # zidane torch.zeros(16,3,720,1280)  # BCHW
            i *= 4  # é‡‡æ · [0, 4, 8, 16]
            if random.random() < 0.5:
                # éšæœºæ•°å°äº0.5å°±ç›´æ¥å°†æŸå¼ å›¾ç‰‡ä¸Šé‡‡æ ·ä¸¤å€è®­ç»ƒ
                im = F.interpolate(img[i].unsqueeze(0).float(), scale_factor=2., mode='bilinear', align_corners=False)[
                    0].type(img[i].type())
                l = label[i]
            else:
                # éšæœºæ•°å¤§äº0.5å°±å°†å››å¼ å›¾ç‰‡(mosaicåçš„)æ‹¼æ¥åˆ°ä¸€å¼ å¤§å›¾ä¸Šè®­ç»ƒ
                im = torch.cat((torch.cat((img[i], img[i + 1]), 1), torch.cat((img[i + 2], img[i + 3]), 1)), 2)
                l = torch.cat((label[i], label[i + 1] + ho, label[i + 2] + wo, label[i + 3] + ho + wo), 0) * s
            img4.append(im)
            label4.append(l)

        for i, l in enumerate(label4):
            l[:, 0] = i  # add target image index for build_targets()

        return torch.stack(img4, 0), torch.cat(label4, 0), path4, shapes4


# Ancillary functions --------------------------------------------------------------------------------------------------
def load_image(self, i):
    """
    ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__getitem__å‡½æ•°å’Œload_mosaicæ¨¡å—ä¸­
    ä»selfæˆ–è€…ä»å¯¹åº”å›¾ç‰‡è·¯å¾„ä¸­è½½å…¥å¯¹åº”indexçš„å›¾ç‰‡ å¹¶å°†åŸå›¾ä¸­hwä¸­è¾ƒå¤§è€…æ‰©å±•åˆ°self.img_size, è¾ƒå°è€…åŒæ¯”ä¾‹æ‰©å±•
    loads 1 image from dataset, returns img, original hw, resized hw
    :params self: ä¸€èˆ¬æ˜¯å¯¼å…¥LoadImagesAndLabelsä¸­çš„self
    :param index: å½“å‰å›¾ç‰‡çš„index
    :return: img: resizeåçš„å›¾ç‰‡
            (h0, w0): hw_original  åŸå›¾çš„hw
            img.shape[:2]: hw_resized resizeåçš„å›¾ç‰‡hw(hwä¸­è¾ƒå¤§è€…æ‰©å±•åˆ°self.img_size, è¾ƒå°è€…åŒæ¯”ä¾‹æ‰©å±•)
    """
    # loads 1 image from dataset index 'i', returns im, original hw, resized hw
    # æŒ‰indexä»self.imgsä¸­è½½å…¥å½“å‰å›¾ç‰‡, ä½†æ˜¯ç”±äºç¼“å­˜çš„å†…å®¹ä¸€èˆ¬ä¼šä¸å¤Ÿ, æ‰€ä»¥æˆ‘ä»¬ä¸€èˆ¬ä¸ä¼šç”¨self.imgs(cache)ä¿å­˜æ‰€æœ‰çš„å›¾ç‰‡
    im = self.imgs[i]
    # å›¾ç‰‡æ˜¯ç©ºçš„è¯, å°±ä»å¯¹åº”æ–‡ä»¶è·¯å¾„è¯»å‡ºè¿™å¼ å›¾ç‰‡
    if im is None:  # not cached in ram    ä¸€èˆ¬éƒ½ä¸ä¼šä½¿ç”¨cacheç¼“å­˜åˆ°self.imgsä¸­
        npy = self.img_npy[i]
        if npy and npy.exists():  # load npy
            im = np.load(npy)
        else:  # read image
            path = self.img_files[i]    # å›¾ç‰‡è·¯å¾„
            im = cv2.imread(path)  # BGR è¯»å‡ºBGRå›¾ç‰‡  (335, 500, 3)  HWC
            assert im is not None, 'Image Not Found ' + path
        h0, w0 = im.shape[:2]  # orig hw
        r = self.img_size / max(h0, w0)  # ratio
        if r != 1:  # if sizes are not equal
            im = cv2.resize(im, (int(w0 * r), int(h0 * r)),
                            interpolation=cv2.INTER_AREA if r < 1 and not self.augment else cv2.INTER_LINEAR)
        return im, (h0, w0), im.shape[:2]  # im, hw_original, hw_resized
    else:
        return self.imgs[i], self.img_hw0[i], self.img_hw[i]  # im, hw_original, hw_resized


def load_mosaic(self, index):
    # loads images in a 4-mosaic

    labels4, segments4 = [], []
    s = self.img_size
    yc, xc = [int(random.uniform(-x, 2 * s + x)) for x in self.mosaic_border]  # mosaic center x, y
    indices = [index] + random.choices(self.indices, k=3)  # 3 additional image indices
    random.shuffle(indices)
    for i, index in enumerate(indices):
        # Load image
        img, _, (h, w) = load_image(self, index)

        # place img in img4
        if i == 0:  # top left
            img4 = np.full((s * 2, s * 2, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles
            x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)
            x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)
        elif i == 1:  # top right
            x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc
            x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h
        elif i == 2:  # bottom left
            x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)
            x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, w, min(y2a - y1a, h)
        elif i == 3:  # bottom right
            x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)
            x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)

        img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]
        padw = x1a - x1b
        padh = y1a - y1b

        # Labels
        labels, segments = self.labels[index].copy(), self.segments[index].copy()
        if labels.size:
            labels[:, 1:] = xywhn2xyxy(labels[:, 1:], w, h, padw, padh)  # normalized xywh to pixel xyxy format
            segments = [xyn2xy(x, w, h, padw, padh) for x in segments]
        labels4.append(labels)
        segments4.extend(segments)

    # Concat/clip labels
    labels4 = np.concatenate(labels4, 0)
    for x in (labels4[:, 1:], *segments4):
        np.clip(x, 0, 2 * s, out=x)  # clip when using random_perspective()
    # img4, labels4 = replicate(img4, labels4)  # replicate

    # Augment
    img4, labels4, segments4 = copy_paste(img4, labels4, segments4, p=self.hyp['copy_paste'])
    img4, labels4 = random_perspective(img4, labels4, segments4,
                                       degrees=self.hyp['degrees'],
                                       translate=self.hyp['translate'],
                                       scale=self.hyp['scale'],
                                       shear=self.hyp['shear'],
                                       perspective=self.hyp['perspective'],
                                       border=self.mosaic_border)  # border to remove

    return img4, labels4


def load_mosaic9(self, index):
    # loads images in a 9-mosaic

    labels9, segments9 = [], []
    s = self.img_size
    indices = [index] + random.choices(self.indices, k=8)  # 8 additional image indices
    random.shuffle(indices)
    for i, index in enumerate(indices):
        # Load image
        img, _, (h, w) = load_image(self, index)

        # place img in img9
        if i == 0:  # center
            img9 = np.full((s * 3, s * 3, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles
            h0, w0 = h, w
            c = s, s, s + w, s + h  # xmin, ymin, xmax, ymax (base) coordinates
        elif i == 1:  # top
            c = s, s - h, s + w, s
        elif i == 2:  # top right
            c = s + wp, s - h, s + wp + w, s
        elif i == 3:  # right
            c = s + w0, s, s + w0 + w, s + h
        elif i == 4:  # bottom right
            c = s + w0, s + hp, s + w0 + w, s + hp + h
        elif i == 5:  # bottom
            c = s + w0 - w, s + h0, s + w0, s + h0 + h
        elif i == 6:  # bottom left
            c = s + w0 - wp - w, s + h0, s + w0 - wp, s + h0 + h
        elif i == 7:  # left
            c = s - w, s + h0 - h, s, s + h0
        elif i == 8:  # top left
            c = s - w, s + h0 - hp - h, s, s + h0 - hp

        padx, pady = c[:2]
        x1, y1, x2, y2 = [max(x, 0) for x in c]  # allocate coords

        # Labels
        labels, segments = self.labels[index].copy(), self.segments[index].copy()
        if labels.size:
            labels[:, 1:] = xywhn2xyxy(labels[:, 1:], w, h, padx, pady)  # normalized xywh to pixel xyxy format
            segments = [xyn2xy(x, w, h, padx, pady) for x in segments]
        labels9.append(labels)
        segments9.extend(segments)

        # Image
        img9[y1:y2, x1:x2] = img[y1 - pady:, x1 - padx:]  # img9[ymin:ymax, xmin:xmax]
        hp, wp = h, w  # height, width previous

    # Offset
    yc, xc = [int(random.uniform(0, s)) for _ in self.mosaic_border]  # mosaic center x, y
    img9 = img9[yc:yc + 2 * s, xc:xc + 2 * s]

    # Concat/clip labels
    labels9 = np.concatenate(labels9, 0)
    labels9[:, [1, 3]] -= xc
    labels9[:, [2, 4]] -= yc
    c = np.array([xc, yc])  # centers
    segments9 = [x - c for x in segments9]

    for x in (labels9[:, 1:], *segments9):
        np.clip(x, 0, 2 * s, out=x)  # clip when using random_perspective()
    # img9, labels9 = replicate(img9, labels9)  # replicate

    # Augment
    img9, labels9 = random_perspective(img9, labels9, segments9,
                                       degrees=self.hyp['degrees'],
                                       translate=self.hyp['translate'],
                                       scale=self.hyp['scale'],
                                       shear=self.hyp['shear'],
                                       perspective=self.hyp['perspective'],
                                       border=self.mosaic_border)  # border to remove

    return img9, labels9


def create_folder(path='./new'):
    # Create folder
    if os.path.exists(path):
        shutil.rmtree(path)  # delete output folder
    os.makedirs(path)  # make new output folder


def flatten_recursive(path='../datasets/coco128'):
    # Flatten a recursive directory by bringing all files to top level
    new_path = Path(path + '_flat')
    create_folder(new_path)
    for file in tqdm(glob.glob(str(Path(path)) + '/**/*.*', recursive=True)):
        shutil.copyfile(file, new_path / Path(file).name)


def extract_boxes(path='../datasets/coco128'):  # from utils.datasets import *; extract_boxes()
    # Convert detection dataset into classification dataset, with one directory per class
    path = Path(path)  # images dir
    shutil.rmtree(path / 'classifier') if (path / 'classifier').is_dir() else None  # remove existing
    files = list(path.rglob('*.*'))
    n = len(files)  # number of files
    for im_file in tqdm(files, total=n):
        if im_file.suffix[1:] in IMG_FORMATS:
            # image
            im = cv2.imread(str(im_file))[..., ::-1]  # BGR to RGB
            h, w = im.shape[:2]

            # labels
            lb_file = Path(img2label_paths([str(im_file)])[0])
            if Path(lb_file).exists():
                with open(lb_file, 'r') as f:
                    lb = np.array([x.split() for x in f.read().strip().splitlines()], dtype=np.float32)  # labels

                for j, x in enumerate(lb):
                    c = int(x[0])  # class
                    f = (path / 'classifier') / f'{c}' / f'{path.stem}_{im_file.stem}_{j}.jpg'  # new filename
                    if not f.parent.is_dir():
                        f.parent.mkdir(parents=True)

                    b = x[1:] * [w, h, w, h]  # box
                    # b[2:] = b[2:].max()  # rectangle to square
                    b[2:] = b[2:] * 1.2 + 3  # pad
                    b = xywh2xyxy(b.reshape(-1, 4)).ravel().astype(np.int)

                    b[[0, 2]] = np.clip(b[[0, 2]], 0, w)  # clip boxes outside of image
                    b[[1, 3]] = np.clip(b[[1, 3]], 0, h)
                    assert cv2.imwrite(str(f), im[b[1]:b[3], b[0]:b[2]]), f'box failure in {f}'


def autosplit(path='../datasets/coco128/images', weights=(0.9, 0.1, 0.0), annotated_only=False):
    """ Autosplit a dataset into train/val/test splits and save path/autosplit_*.txt files
    Usage: from utils.datasets import *; autosplit()
    Arguments
        path:            Path to images directory
        weights:         Train, val, test weights (list, tuple)
        annotated_only:  Only use images with an annotated txt file
    """
    path = Path(path)  # images dir
    files = sum([list(path.rglob(f"*.{img_ext}")) for img_ext in IMG_FORMATS], [])  # image files only
    n = len(files)  # number of files
    random.seed(0)  # for reproducibility
    indices = random.choices([0, 1, 2], weights=weights, k=n)  # assign each image to a split

    txt = ['autosplit_train.txt', 'autosplit_val.txt', 'autosplit_test.txt']  # 3 txt files
    [(path.parent / x).unlink(missing_ok=True) for x in txt]  # remove existing

    print(f'Autosplitting images from {path}' + ', using *.txt labeled images only' * annotated_only)
    for i, img in tqdm(zip(indices, files), total=n):
        if not annotated_only or Path(img2label_paths([str(img)])[0]).exists():  # check label
            with open(path.parent / txt[i], 'a') as f:
                f.write('./' + img.relative_to(path.parent).as_posix() + '\n')  # add image to txt file


def verify_image_label(args):
    """
    ç”¨åœ¨cache_labelså‡½æ•°ä¸­
    æ£€æµ‹æ•°æ®é›†ä¸­æ¯å¼ å›¾ç‰‡å’Œæ¯å¼ laeblæ˜¯å¦å®Œå¥½
    å›¾ç‰‡æ–‡ä»¶: å†…å®¹ã€æ ¼å¼ã€å¤§å°ã€å®Œæ•´æ€§
    labelæ–‡ä»¶: æ¯ä¸ªgtå¿…é¡»æ˜¯çŸ©å½¢(æ¯è¡Œéƒ½å¾—æ˜¯5ä¸ªæ•° class+xywh) + æ ‡ç­¾æ˜¯å¦å…¨éƒ¨>=0 + æ ‡ç­¾åæ ‡xywhæ˜¯å¦å½’ä¸€åŒ– + æ ‡ç­¾ä¸­æ˜¯å¦æœ‰é‡å¤çš„åæ ‡
    :params im_file: æ•°æ®é›†ä¸­ä¸€å¼ å›¾ç‰‡çš„pathç›¸å¯¹è·¯å¾„
    :params lb_file: æ•°æ®é›†ä¸­ä¸€å¼ å›¾ç‰‡çš„labelç›¸å¯¹è·¯å¾„
    :params prefix: æ—¥å¿—å¤´éƒ¨ä¿¡æ¯(å½©æ‰“é«˜äº®éƒ¨åˆ†)
    :return im_file: å½“å‰è¿™å¼ å›¾ç‰‡çš„pathç›¸å¯¹è·¯å¾„
    :return l: [gt_num, cls+xywh(normalized)]
               å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ lå°±å­˜å‚¨åŸlabel(å…¨éƒ¨æ˜¯æ­£å¸¸çŸ©å½¢æ ‡ç­¾)
               å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾  lå°±å­˜å‚¨ç»è¿‡segments2boxeså¤„ç†å¥½çš„æ ‡ç­¾(æ­£å¸¸çŸ©å½¢æ ‡ç­¾ä¸å¤„ç† å¤šè¾¹å½¢æ ‡ç­¾è½¬åŒ–ä¸ºçŸ©å½¢æ ‡ç­¾)
    :return shape: å½“å‰è¿™å¼ å›¾ç‰‡çš„å½¢çŠ¶ shape
    :return segments: å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å­˜å‚¨None
                      å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å°±æŠŠè¿™å¼ å›¾ç‰‡çš„æ‰€æœ‰labelå­˜å‚¨åˆ°segmentsä¸­(è‹¥å¹²ä¸ªæ­£å¸¸gt è‹¥å¹²ä¸ªå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, xy1...]
    :return nm: number missing å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦ä¸¢å¤±         ä¸¢å¤±=1    å­˜åœ¨=0
    :return nf: number found å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦å­˜åœ¨           å­˜åœ¨=1    ä¸¢å¤±=0
    :return ne: number empty å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦æ˜¯ç©ºçš„         ç©ºçš„=1    æ²¡ç©º=0
    :return nc: number corrupt å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ–‡ä»¶æ˜¯å¦æ˜¯ç ´æŸçš„  ç ´æŸçš„=1  æ²¡ç ´æŸ=0
    :return msg: è¿”å›çš„msgä¿¡æ¯  labelæ–‡ä»¶å®Œå¥½=â€˜â€™  labelæ–‡ä»¶ç ´æŸ=warningä¿¡æ¯
    """
    # Verify one image-label pair
    im_file, lb_file, prefix = args
    nm, nf, ne, nc, msg, segments = 0, 0, 0, 0, '', []  # number (missing, found, empty, corrupt), message, segments
    try:
        # æ£€æŸ¥è¿™å¼ å›¾ç‰‡(å†…å®¹ã€æ ¼å¼ã€å¤§å°ã€å®Œæ•´æ€§) verify images
        im = Image.open(im_file)    # æ‰“å¼€å›¾ç‰‡æ–‡ä»¶
        im.verify()  # PIL verify   æ£€æŸ¥å›¾ç‰‡å†…å®¹å’Œæ ¼å¼æ˜¯å¦æ­£å¸¸
        shape = exif_size(im)  # image size å½“å‰å›¾ç‰‡çš„å¤§å°
        assert (shape[0] > 9) & (shape[1] > 9), f'image size {shape} <10 pixels'    # å›¾ç‰‡å¤§å°å¿…é¡»å¤§äº9ä¸ªpixels
        assert im.format.lower() in IMG_FORMATS, f'invalid image format {im.format}'    # å›¾ç‰‡æ ¼å¼å¿…é¡»åœ¨img_formatä¸­
        if im.format.lower() in ('jpg', 'jpeg'):    # æ£€æŸ¥jpgæ ¼å¼æ–‡ä»¶
            with open(im_file, 'rb') as f:
                # f.seek: -2 åç§»é‡ å‘æ–‡ä»¶å¤´æ–¹å‘ä¸­ç§»åŠ¨çš„å­—èŠ‚æ•°   2 ç›¸å¯¹ä½ç½® ä»æ–‡ä»¶å°¾å¼€å§‹åç§»
                f.seek(-2, 2)
                # f.read(): è¯»å–å›¾ç‰‡æ–‡ä»¶  æŒ‡ä»¤: \xff\xd9  æ£€æµ‹æ•´å¼ å›¾ç‰‡æ˜¯å¦å®Œæ•´  å¦‚æœä¸å®Œæ•´å°±è¿”å›corrupted JPEG
                assert f.read() == b'\xff\xd9', 'corrupted JPEG'

        # verify labels
        segments = []  # instance segments  å­˜æ”¾è¿™å¼ å›¾æ‰€æœ‰gtæ¡†çš„ä¿¡æ¯(åŒ…å«segmentså¤šè¾¹å½¢: labelæŸä¸€åˆ—æ•°å¤§äº8)
        if os.path.isfile(lb_file): # å¦‚æœè¿™ä¸ªlabelè·¯å¾„å­˜åœ¨
            nf = 1  # label found
            with open(lb_file, 'r') as f:   # è¯»å–labelæ–‡ä»¶
                # è¯»å–å½“å‰labelæ–‡ä»¶çš„æ¯ä¸€è¡Œ: æ¯ä¸€è¡Œéƒ½æ˜¯å½“å‰å›¾ç‰‡çš„ä¸€ä¸ªgt
                l = [x.split() for x in f.read().strip().splitlines() if len(x)]
                # any() å‡½æ•°ç”¨äºåˆ¤æ–­ç»™å®šçš„å¯è¿­ä»£å‚æ•° æ˜¯å¦å…¨éƒ¨ä¸ºFalse,åˆ™è¿”å› False; å¦‚æœæœ‰ä¸€ä¸ªä¸º True,åˆ™è¿”å›True
                # å¦‚æœå½“å‰å›¾ç‰‡çš„labelæ–‡ä»¶æŸä¸€åˆ—æ•°å¤§äº8, åˆ™è®¤ä¸ºlabelæ˜¯å­˜åœ¨segmentçš„polygonç‚¹(å¤šè¾¹å½¢)  å°±ä¸æ˜¯çŸ©é˜µ åˆ™å°†labelä¿¡æ¯å­˜å…¥segmentä¸­
                if any([len(x) > 8 for x in l]):  # is segment
                    # å½“å‰å›¾ç‰‡ä¸­æ‰€æœ‰gtæ¡†çš„ç±»åˆ«
                    classes = np.array([x[0] for x in l], dtype=np.float32)
                    # è·å¾—è¿™å¼ å›¾ä¸­æ‰€æœ‰gtæ¡†çš„labelä¿¡æ¯(åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾)
                    # å› ä¸ºsegmentæ ‡ç­¾å¯ä»¥æ˜¯ä¸åŒé•¿åº¦ï¼Œæ‰€ä»¥è¿™é‡Œsegmentsæ˜¯ä¸€ä¸ªåˆ—è¡¨ [gt_num, xy1...(normalized)]
                    segments = [np.array(x[1:], dtype=np.float32).reshape(-1, 2) for x in l]  # (cls, xy1...)
                    # è·å¾—è¿™å¼ å›¾ä¸­æ‰€æœ‰gtæ¡†çš„labelä¿¡æ¯(ä¸åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾)
                    # segments(å¤šè¾¹å½¢) -> bbox(æ­£æ–¹å½¢), å¾—åˆ°æ–°æ ‡ç­¾  [gt_num, cls+xywh(normalized)]
                    l = np.concatenate((classes.reshape(-1, 1), segments2boxes(segments)), 1)  # (cls, xywh)
                l = np.array(l, dtype=np.float32)
            if len(l):
                # åˆ¤æ–­æ ‡ç­¾æ˜¯å¦æœ‰äº”åˆ—
                assert l.shape[1] == 5, 'labels require 5 columns each'
                # åˆ¤æ–­æ ‡ç­¾æ˜¯å¦å…¨éƒ¨>=0
                assert (l >= 0).all(), 'negative labels'
                # åˆ¤æ–­æ ‡ç­¾åæ ‡x y w hæ˜¯å¦å½’ä¸€åŒ–
                assert (l[:, 1:] <= 1).all(), 'non-normalized or out of bounds coordinate labels'
                # åˆ¤æ–­æ ‡ç­¾ä¸­æ˜¯å¦æœ‰é‡å¤çš„åæ ‡
                assert np.unique(l, axis=0).shape[0] == l.shape[0], 'duplicate labels'
            else:
                ne = 1  # label empty   l.shape[0] == 0åˆ™ä¸ºç©ºçš„æ ‡ç­¾ï¼Œne=1
                l = np.zeros((0, 5), dtype=np.float32)
        else:
            nm = 1  # label missing     ä¸å­˜åœ¨æ ‡ç­¾æ–‡ä»¶ï¼Œåˆ™nm = 1
            l = np.zeros((0, 5), dtype=np.float32)
        return im_file, l, shape, segments, nm, nf, ne, nc, msg
    except Exception as e:
        nc = 1
        msg = f'{prefix}WARNING: Ignoring corrupted image and/or label {im_file}: {e}'
        return [None, None, None, None, nm, nf, ne, nc, msg]


def dataset_stats(path='coco128.yaml', autodownload=False, verbose=False, profile=False, hub=False):
    """ Return dataset statistics dictionary with images and instances counts per split per class
    To run in parent directory: export PYTHONPATH="$PWD/yolov5"
    Usage1: from utils.datasets import *; dataset_stats('coco128.yaml', autodownload=True)
    Usage2: from utils.datasets import *; dataset_stats('../datasets/coco128_with_yaml.zip')
    Arguments
        path:           Path to data.yaml or data.zip (with data.yaml inside data.zip)
        autodownload:   Attempt to download dataset if not found locally
        verbose:        Print stats dictionary
    """

    def round_labels(labels):
        # Update labels to integer class and 6 decimal place floats
        return [[int(c), *[round(x, 4) for x in points]] for c, *points in labels]

    def unzip(path):
        # Unzip data.zip TODO: CONSTRAINT: path/to/abc.zip MUST unzip to 'path/to/abc/'
        if str(path).endswith('.zip'):  # path is data.zip
            assert Path(path).is_file(), f'Error unzipping {path}, file not found'
            assert os.system(f'unzip -q {path} -d {path.parent}') == 0, f'Error unzipping {path}'
            dir = path.with_suffix('')  # dataset directory
            return True, str(dir), next(dir.rglob('*.yaml'))  # zipped, data_dir, yaml_path
        else:  # path is data.yaml
            return False, None, path

    def hub_ops(f, max_dim=1920):
        # HUB ops for 1 image 'f'
        im = Image.open(f)
        r = max_dim / max(im.height, im.width)  # ratio
        if r < 1.0:  # image too large
            im = im.resize((int(im.width * r), int(im.height * r)))
        im.save(im_dir / Path(f).name, quality=75)  # save

    zipped, data_dir, yaml_path = unzip(Path(path))
    with open(check_yaml(yaml_path), errors='ignore') as f:
        data = yaml.safe_load(f)  # data dict
        if zipped:
            data['path'] = data_dir  # TODO: should this be dir.resolve()?
    check_dataset(data, autodownload)  # download dataset if missing
    hub_dir = Path(data['path'] + ('-hub' if hub else ''))
    stats = {'nc': data['nc'], 'names': data['names']}  # statistics dictionary
    for split in 'train', 'val', 'test':
        if data.get(split) is None:
            stats[split] = None  # i.e. no test set
            continue
        x = []
        dataset = LoadImagesAndLabels(data[split])  # load dataset
        for label in tqdm(dataset.labels, total=dataset.n, desc='Statistics'):
            x.append(np.bincount(label[:, 0].astype(int), minlength=data['nc']))
        x = np.array(x)  # shape(128x80)
        stats[split] = {'instance_stats': {'total': int(x.sum()), 'per_class': x.sum(0).tolist()},
                        'image_stats': {'total': dataset.n, 'unlabelled': int(np.all(x == 0, 1).sum()),
                                        'per_class': (x > 0).sum(0).tolist()},
                        'labels': [{str(Path(k).name): round_labels(v.tolist())} for k, v in
                                   zip(dataset.img_files, dataset.labels)]}

        if hub:
            im_dir = hub_dir / 'images'
            im_dir.mkdir(parents=True, exist_ok=True)
            for _ in tqdm(ThreadPool(NUM_THREADS).imap(hub_ops, dataset.img_files), total=dataset.n, desc='HUB Ops'):
                pass

    # Profile
    stats_path = hub_dir / 'stats.json'
    if profile:
        for _ in range(1):
            file = stats_path.with_suffix('.npy')
            t1 = time.time()
            np.save(file, stats)
            t2 = time.time()
            x = np.load(file, allow_pickle=True)
            print(f'stats.npy times: {time.time() - t2:.3f}s read, {t2 - t1:.3f}s write')

            file = stats_path.with_suffix('.json')
            t1 = time.time()
            with open(file, 'w') as f:
                json.dump(stats, f)  # save stats *.json
            t2 = time.time()
            with open(file, 'r') as f:
                x = json.load(f)  # load hyps dict
            print(f'stats.json times: {time.time() - t2:.3f}s read, {t2 - t1:.3f}s write')

    # Save, print and return
    if hub:
        print(f'Saving {stats_path.resolve()}...')
        with open(stats_path, 'w') as f:
            json.dump(stats, f)  # save stats.json
    if verbose:
        print(json.dumps(stats, indent=2, sort_keys=False))
    return stats
